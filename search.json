[
  {
    "objectID": "seminario3.html",
    "href": "seminario3.html",
    "title": "Introdução",
    "section": "",
    "text": "Os seminários da disciplina consistem em uma apresentação coletiva (da turma) de um artigo mais recente sobre tópicos diretamente relacionados ao conteúdo visto em sala. A ideia é que a turma como um todo estude os artigos mais recentes da área e discuta esses trabalhos em sala. Em cada sessão, discutimos dois artigos recentes relacionados aos tópicos abordados nas aulas teóricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canadá) – veja aqui a proposta original. A proposta consiste em fazer uma encenação de papéis (role play) científicos para a apresentação do seminário. Nessa proposta, cada grupo cumprirá um papel na apresentação. Ao final, uma apresentação em formato de slides e um documento textual são produzidos. A apresentação é usada em sala de aula para fomentar as discussões, enquanto o documento fornece uma descrição textual das impressões da turma com a intenção de descrever o tema do artigo para um público amplo interessado em aprendizado de máquina e mineração de dados.\nSão apresentados a seguir os artigos discutidos no semestre 2025/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\n\nModeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics\nAutores: A.-W. de Leeuw, R. van Baar, A. Knobbe, and S. van der Zwaard. 2022\nDOI: 10.3390/s22207996\n\n\n\n\n\nExceptional Subitizing Patterns: Exploring Mathematical Abilities of Finnish Primary School Children with Piecewise Linear Regression\nAutores: R. M. Schouten, W. Duivesteijn, P. Räsänen, J. M. Paul, and M. Pechenizkiy. 2024\nDOI: 10.1007/978-3-031-70381-2_5"
  },
  {
    "objectID": "seminario3.html#artigo-5seminario_art5",
    "href": "seminario3.html#artigo-5seminario_art5",
    "title": "Introdução",
    "section": "",
    "text": "Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics\nAutores: A.-W. de Leeuw, R. van Baar, A. Knobbe, and S. van der Zwaard. 2022\nDOI: 10.3390/s22207996"
  },
  {
    "objectID": "seminario3.html#artigo-6seminario_art6",
    "href": "seminario3.html#artigo-6seminario_art6",
    "title": "Introdução",
    "section": "",
    "text": "Exceptional Subitizing Patterns: Exploring Mathematical Abilities of Finnish Primary School Children with Piecewise Linear Regression\nAutores: R. M. Schouten, W. Duivesteijn, P. Räsänen, J. M. Paul, and M. Pechenizkiy. 2024\nDOI: 10.1007/978-3-031-70381-2_5"
  },
  {
    "objectID": "seminario2/artigo3.html",
    "href": "seminario2/artigo3.html",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "",
    "text": "O machine learning (aprendizado de máquina) tem permitido avanços incríveis, indo do diagnóstico de câncer à detecção de fraudes. Porém, muitos desses modelos entregam respostas sem explicações. Foi para resolver esse problema que surgiu o DiffNaps.\nBaseado no artigo “Finding Interpretable Class-Specific Patterns Through Efficient Neural Search”, o DiffNaps é uma arquitetura de rede neural criada para extrair padrões específicos de cada classe, legíveis por humanos, mesmo em bases de dados muito grandes, como dados genômicos.\n\n\nImagine por um momento que você tem um conjunto de dados massivo — por exemplo, dados de expressão gênica para diferentes tipos de câncer. O objetivo é identificar padrões específicos dentro desses dados que separem claramente um tipo de câncer do outro, de uma forma que seja facilmente compreendida por especialistas da área, como biólogos. Ou seja, não se trata apenas de obter uma classificação precisa, mas também de entender por que essa classificação foi feita.\nMuitos modelos de aprendizado de máquina são excelentes em prever, mas seus processos de tomada de decisão costumam ser opacos. Este artigo é um estudo que enfatiza ambos os aspectos: ele prioriza a interpretabilidade. Os autores argumentam que, em campos como a biologia, entender os padrões subjacentes é crucial para o desenvolvimento de novos tratamentos e terapias."
  },
  {
    "objectID": "seminario2/artigo3.html#introdução",
    "href": "seminario2/artigo3.html#introdução",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "",
    "text": "O machine learning (aprendizado de máquina) tem permitido avanços incríveis, indo do diagnóstico de câncer à detecção de fraudes. Porém, muitos desses modelos entregam respostas sem explicações. Foi para resolver esse problema que surgiu o DiffNaps.\nBaseado no artigo “Finding Interpretable Class-Specific Patterns Through Efficient Neural Search”, o DiffNaps é uma arquitetura de rede neural criada para extrair padrões específicos de cada classe, legíveis por humanos, mesmo em bases de dados muito grandes, como dados genômicos.\n\n\nImagine por um momento que você tem um conjunto de dados massivo — por exemplo, dados de expressão gênica para diferentes tipos de câncer. O objetivo é identificar padrões específicos dentro desses dados que separem claramente um tipo de câncer do outro, de uma forma que seja facilmente compreendida por especialistas da área, como biólogos. Ou seja, não se trata apenas de obter uma classificação precisa, mas também de entender por que essa classificação foi feita.\nMuitos modelos de aprendizado de máquina são excelentes em prever, mas seus processos de tomada de decisão costumam ser opacos. Este artigo é um estudo que enfatiza ambos os aspectos: ele prioriza a interpretabilidade. Os autores argumentam que, em campos como a biologia, entender os padrões subjacentes é crucial para o desenvolvimento de novos tratamentos e terapias."
  },
  {
    "objectID": "seminario2/artigo3.html#como-o-diffnaps-funciona",
    "href": "seminario2/artigo3.html#como-o-diffnaps-funciona",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "2 Como o DiffNaps Funciona",
    "text": "2 Como o DiffNaps Funciona\nDiffNaps, abreviação de Differential Pattern Finding Neural Architecture for Pattern Search (Arquitetura Neural de Busca de Padrões Diferenciais). É uma rede neural binária, o que significa que utiliza pesos e ativações binários, 0 ou 1. Isso torna os padrões aprendidos diretamente interpretáveis. É um autocodificador binário de duas camadas combinado com uma classificação head. O autocodificador reconstrói os dados de entrada, enquanto a classificação head garante que os padrões aprendidos sejam discriminativos entre as classes.\nO autocodificador aprende a compactar os dados em uma representação de menor dimensão, o gargalo, e então os reconstrói. No DiffNaps, essa camada de gargalo representa os padrões aprendidos. Como a rede é binária, cada neurônio nessa camada corresponde a um padrão específico de coocorrências de características.\nA classificação head então usa esses padrões para classificar novos pontos de dados. Assim, os padrões são essencialmente representados pelos pesos na rede. Os autores binarizam os pesos usando um limite. Assim, cada peso se torna 0 ou 1. Um valor 1 indica que uma característica específica faz parte do padrão representado por aquele neurônio. Os padrões são então extraídos observando quais características têm 1 no vetor de peso para cada neurônio. A Figura 1 ilustra a arquitetura do DiffNaps. Podemos ver as duas principais partes: o autoencoder binário responsável pela reconstrução dos dados de entrada e a classificação head, que força os padrões aprendidos a serem úteis para distinguir entre classes. A Figura 1 ilustra a arquitetura do DiffNaps.\n\nFigura 1\n\n\n\nArquitetura do DiffNaps"
  },
  {
    "objectID": "seminario2/artigo3.html#estudo-de-caso-genômica-do-câncer-de-mama",
    "href": "seminario2/artigo3.html#estudo-de-caso-genômica-do-câncer-de-mama",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "3 Estudo de Caso: Genômica do Câncer de Mama",
    "text": "3 Estudo de Caso: Genômica do Câncer de Mama\nAplicando o DiffNaps a dados de câncer de mama, os autores extraíram 146 padrões de expressão gênica que separam tecidos cancerosos de tecidos saudáveis. Muitos desses padrões se alinhavam a vias conhecidas, como MAPK, WNT e PPAR, mas também descobriu novos padrões que podem representar relações biológicas até então desconhecidas. Esses padrões foram validados usando a análise da via KEGG, confirmando sua relevância para a progressão e o comportamento dos subtipos do câncer de mama. Isso demonstra que o DiffNaps pode auxiliar não apenas na previsão, mas também na descoberta científica."
  },
  {
    "objectID": "seminario2/artigo3.html#como-se-compara-a-outros-métodos",
    "href": "seminario2/artigo3.html#como-se-compara-a-outros-métodos",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "4 Como se Compara a Outros Métodos",
    "text": "4 Como se Compara a Outros Métodos\nOs autores conduziram experimentos com dados sintéticos e do mundo real, comparando o DiffNaps a diversos métodos de última geração, incluindo árvores de decisão, listas de regras e outras técnicas de mineração de padrões. Em conjuntos de dados sintéticos, eles testaram a capacidade do modelo de recuperar padrões conhecidos sob ruído e complexidade crescentes. Em geral, o DiffNaps demonstrou desempenho superior em termos de precisão, escalabilidade e interpretabilidade, especialmente ao lidar com dados de alta dimensão e dados ruidosos. Os métodos existentes frequentemente apresentavam dificuldades de escalabilidade ou produziam muitos padrões redundantes, dificultando a interpretação.\nPara melhor ilustrar o desempenho do DiffNaps em conjuntos de dados do mundo real, o Quadro 1 resume a aplicação do modelo em vários conjuntos de dados do mundo real. Estes incluem conjuntos de dados médicos e genômicos com tamanhos e níveis de complexidade amplamente variados. A tabela relata o número de amostras e características, o número de classes, quantos padrões o DiffNaps extraiu e o desempenho desses padrões na distinção entre classes usando a métrica AUC (Área Sob a Curva). Esses resultados demonstram a escalabilidade e a eficácia dos DiffNaps na produção de padrões interpretáveis ​​a partir de dados de alta dimensão.\n\nQuadro 1 Desempenho do DiffNaps em Bases de Dados Reais\n\n\n\n\n\n\n\n\n\n\n\n\nConjunto\nDomínio\nAmostras (n)\nAtributos (m)\nClasses (K)\nPadrões\nAUC\n\n\n\n\nCardio\nSaúde cardiovascular\n68 000\n45\n2\n14\n0,56\n\n\nDisease\nDiagnóstico baseado em sintomas\n5 000\n131\n41\n838\n0,84\n\n\nBRCA-N\nCâncer de mama vs. tecido normal\n222\n20 000\n2\n146\n0,91\n\n\nBRCA-S\nSubtipos de câncer de mama\n187\n20 000\n4\n1 000\n0,86\n\n\nGenomes\nVariação genética (classificação de população)\n2 500\n225 000\n6\n732\n0,77\n\n\n\nEsses números mostram que o DiffNaps escala para centenas de milhares de atributos e ainda produz padrões interpretáveis."
  },
  {
    "objectID": "seminario2/artigo3.html#casos-de-uso-no-mundo-real",
    "href": "seminario2/artigo3.html#casos-de-uso-no-mundo-real",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "5 Casos de Uso no Mundo Real",
    "text": "5 Casos de Uso no Mundo Real\n\nSaúde Mental em Redes Sociais – Nas plataformas sociais, padrões de texto e comportamento, como queixas de sono e abstinência, podem sugerir sinais precoces de depressão ou ansiedade. O DiffNaps pode revelar sinais de alerta interpretáveis, ajudando os profissionais a agirem mais cedo.\nIoT Industrial e Manutenção - As fábricas são equipadas com milhares de sensores. O DiffNaps consegue detectar padrões como:\n\nVibração X + Temperatura Y + RPM Z → Falha no motor\nEssas regras ajudam os técnicos a corrigir as causas raiz, não apenas os sintomas, e também permitem a manutenção preditiva com explicação.\n\nDetecção de Fraudes Financeiras – As transações bancárias envolvem muitas variáveis, como valores, IPs, dispositivos, registros de data e hora, etc. O DiffNaps pode ajudar a destacar gatilhos de fraude como:\n\nDispositivo novo + Login noturno + Saque alto → Fraude"
  },
  {
    "objectID": "seminario2/artigo3.html#limitações-do-diffnaps",
    "href": "seminario2/artigo3.html#limitações-do-diffnaps",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "6 Limitações do DiffNaps",
    "text": "6 Limitações do DiffNaps\nEmbora o DiffNaps se destaque em tarefas estruturadas e de alta dimensão, ele não é adequado para todos os contextos:\n\nEle não se adapta bem a dados de baixa dimensão (conjuntos de dados com menos atributos e estruturas mais simples).\nAtualmente, ele modela apenas regras conjuntivas baseadas em AND trabalhos futuros podem se estender a disjunções ou cadeias lógicas.\n\nPode exigir muitos recursos de memória (por exemplo, ~40 GB para o conjunto TCGA)."
  },
  {
    "objectID": "seminario2/artigo3.html#impactos-éticos-e-sociais",
    "href": "seminario2/artigo3.html#impactos-éticos-e-sociais",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "7 Impactos Éticos e Sociais",
    "text": "7 Impactos Éticos e Sociais\n\nAmplificação de viés - Se os dados de treinamento forem tendenciosos (por exemplo, sub-representando certos grupos), os padrões aprendidos podem reforçar esse viés. Por exemplo, padrões em dados genômicos ou financeiros podem refletir desigualdades sociais.\nPrivacidade – Revelar padrões interpretáveis ​​também pode expor informações pessoais confidenciais, especialmente em conjuntos de dados médicos ou comportamentais.\nMau uso – Embora os padrões sejam mais fáceis de ler, eles ainda exigem conhecimento de domínio para serem interpretados corretamente. O uso indevido ou o excesso de confiança nos resultados podem levar a tomadas de decisão equivocadas.\n\nTransparência é ótimo, mas deve ser acompanhada de responsabilidade."
  },
  {
    "objectID": "seminario2/artigo3.html#como-usar-o-diffnaps-passo-a-passo",
    "href": "seminario2/artigo3.html#como-usar-o-diffnaps-passo-a-passo",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "8 Como Usar o DiffNaps Passo a Passo",
    "text": "8 Como Usar o DiffNaps Passo a Passo\n\nPreparar os Dados –\n\n\nFormate seus dados como uma matriz binária (as características são 0 ou 1).\nNormalize entradas de alta dimensão (por exemplo, expressão gênica, sinalizadores * de transação).\nVocê pode binarizar características contínuas definindo um limite (por exemplo, expressão gênica &gt; 0,5 = 1).\n\nCada linha é uma instância de dados e cada coluna é uma característica.\n\nConfigurar o Ambiente - Certifique-se de que o Python 3.8+ esteja instalado. Em seguida, clone o projeto e instale as dependências:\ngit clone https://github.com/nilspwalter/diffnaps\ncd diffnaps\npip install -r requirements.txt \nCriar Arquivo de Configuração (JSON) -\n{\n  \"dataset\": \"data/breast_cancer.csv\",\n  \"n_epochs\": 500,\n  \"lr\": 0.01,\n  \"batch_size\": 64\n}\nTrainar o Modelo - Use o script fornecido no repositório:\npython train.py --config configs/breast_cancer.json\nInterpretar os Padrões – O script gera arquivos .csv onde cada linha é um padrão e cada coluna indica se o atributo faz parte dele. Visualize ou exporte conforme a necessidade."
  },
  {
    "objectID": "seminario2/artigo3.html#conclusão",
    "href": "seminario2/artigo3.html#conclusão",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "9 Conclusão",
    "text": "9 Conclusão\nA capacidade de descobrir padrões interpretáveis ​​e específicos de classe em dados biológicos de alta dimensão representa um avanço significativo na pesquisa. O DiffNaps oferece uma ferramenta poderosa para que pesquisadores obtenham insights mais profundos sobre processos biológicos complexos e, potencialmente, acelerem o desenvolvimento de novos tratamentos e diagnósticos. É uma abordagem promissora com grande potencial para pesquisas futuras."
  },
  {
    "objectID": "seminario2/artigo3.html#referências",
    "href": "seminario2/artigo3.html#referências",
    "title": "Artigo 3: Interpretable Patterns from Neural Networks: Creating Meaning from Complex Data",
    "section": "10 Referências",
    "text": "10 Referências\n\nWalter, N. P.; Fischer, J.; Vreeken, J. (2024). Finding Interpretable Class-Specific Patterns Through Efficient Neural Search. AAAI 38(8): 9062-9070.\nProjeto SPMF – https://www.philippe-fournier-viger.com/spmf/\nRepositório DiffNaps – https://github.com/nilspwalter/diffnaps"
  },
  {
    "objectID": "seminario1/artigo2.html",
    "href": "seminario1/artigo2.html",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "",
    "text": "A mineração de episódios é um problema similar à mineração de sequências, onde o objetivo é encontrar episódios (sequências de eventos) frequntes. Isso é feito a partir de uma sequência única com eventos temporais, com timestamp e com ou sem ordem (ou, ainda, com ordem parcial). Esse problema pode ser aplicado, por exemplo, na detecção de episódios que precedem quedas ou sobrecargas da rede elétrica.\nAs soluções existentes para esse problema são baseadas em gerações de episódios maximais, episódios fechados e episódios geradores. Elas lidam apenas com episódios em série e, em sua maioria, em sequências simples, onde existe apenas um episódio por timestamp."
  },
  {
    "objectID": "seminario1/artigo2.html#emdo-e-emdo-p",
    "href": "seminario1/artigo2.html#emdo-e-emdo-p",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "EMDO e EMDO-P",
    "text": "EMDO e EMDO-P\nOs autores do artigo propõem dois novos algoritmos para mineração de episódios: o EMDO (Episode Mining under Distinct Occurences) e o EMDO-P (Episode Mining under Distinct Occurences with Pruning). Eles são capazes de lidar com episódios paralelos e com sequências complexas, onde há mais de um episódio por timestamp. Além disso, uma nova definição de frequência é introduzida e utilizada por esses algoritmos. Isso foi feito pois as definições pré-existentes podem levar a uma sub ou superestimação:\nConsiderando o padrão xy, a imagem abaixo mostra uma definição de frequência que superestima a contagem (todas as ocorrências de x são comparadas com todas as ocorrências de y) para 4:\n\n\n\nJá nessa imagem, temos um exemplo da subestimação para o mesmo padrão, onde são considerados apenas uma ocorrência de x e uma de y, que torna a frequêcia igual a 1:\n\n\n\nPor fim, imagem a seguir ilustra a definição proposta, onde um evento pode ser usado no máximo uma vez, o que resulta em uma frequência igual a 2:"
  },
  {
    "objectID": "seminario1/artigo2.html#conceitos-fundamentais",
    "href": "seminario1/artigo2.html#conceitos-fundamentais",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "Conceitos Fundamentais",
    "text": "Conceitos Fundamentais\nPara entendermos os algoritmos propostos e seu funcionamento, é essencial entender alguns conceitos:\n\nEvento: é um par (tipo do evento, timestamp);\nSequência Simples de Eventos: é um conjunto ordenado de eventos, onde há apenas um evento por timestamp;\n\n\n\n\n\nSequência Complexas de Eventos: é um conjunto de eventos, onde eventos podem ocorrer ao mesmo tempo;\n\n\n\n\n\nEpisódio: é um conjunto de eventos com uma relação de ordem parcial entre eles;\n\nEpisódio Paralelo: é um episódio onde a ordem dos eventos não importa;\nEpisódio Injetivo: é um episódio onde cada evento ocorre apenas uma vez.\n\n\n\nContagem de Ocorrências Distintas\nPara evitar a superestimação ou a subestimação da frequência de eventos, a solução proposta faz a contagem das ocorrências distintas. Dessa forma, um vetor de timestamps em cada evento é utilizado para encontrar a ocorrência de episódios, e o algoritmo encontra o maior conjunto possível e ocorrências distintas.\nPara um episódio ser considerado frequente, seu suporte deve ser maior ou igual ao suporte mínimo definido. O suporte do episódio é calculado pelo tamanho do seu conjunto maximal de ocorrências distintas.\nNa figura a seguir, considerando o episódio xyz, temos o conjunto de ocorrências maximais distintas {[1 2 2], [1 5 4], [6 6 6]}, o que resulta em um suporte igual a 3.\n\n\n\n\n\nRegras de Episódios\nAs regras de episódios são relações do tipo α ⇒ β, que representam que se o episódio α ocorreu, há grandes chances que β ocorra. Essa chance é a representação de uma probabilidade, que vem da confiança da regra, que mede a sua força. Se a confiança for maior que um limite pré-definido, a regra é válida."
  },
  {
    "objectID": "seminario1/artigo2.html#emdo",
    "href": "seminario1/artigo2.html#emdo",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "EMDO",
    "text": "EMDO\nO EMDO é o primeiro algoritmo proposto no artigo, que tem como objetivo achar episódios frequentes. Para isso, ele primeiro encontra todos os episódios de tamanho 1 que são frequentes. Em seguida, esses episódios são combinados para gerar candidatos maiores e o suporte (ocorrências distintas) desses novos episódios é calculado. Além disso, para melhorar o desempenho do algoritmo, a poda dos episódios infrequentes é realizada com base na propriedade da anti-monotonicidade, diminuindo o espaço de busca.\n\nPropriedade da Anti-monotonicidade\nA propriedade da Anti-monotonicidade afirma que, sendo α e β dois episódios de forma que α está contido em β, se o episódio β é frequente então α também é frequente. Da mesma forma, se α é infrequente β também é infrequente."
  },
  {
    "objectID": "seminario1/artigo2.html#emdo-p",
    "href": "seminario1/artigo2.html#emdo-p",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "EMDO-P",
    "text": "EMDO-P\nO algoritmo EMDO-P é o segundo algoritmo proposto pelo artigo, e tem como objetivo encontrar as regras de episódios válidas. Primeiramente, ele executa o EMDO para gerar os episódios frequentes. Em seguida, faz o teste, para um par α e β de episódios frequentes, se a regra α ⇒ β é válida. Utiliza, em seguida, a propriedade da anti-monotonicidade para realizar a poda (pruning) dos ramos infrequentes."
  },
  {
    "objectID": "seminario1/artigo2.html#experimentos",
    "href": "seminario1/artigo2.html#experimentos",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "Experimentos",
    "text": "Experimentos\nO problema proposto é descobrir padrões frequentes em sequências de eventos complexos que acontecem no mesmo timestamp. Os experimentos tem como objetivo avaliar a eficiência e a qualidade dos padrões gerados algoritmos propostos.\nPara isso, foram gerados dados sintéticos com variadas quantidades de sequências, tipos de eventos e timestamps. Os experimentos foram separados em análise de descoberta de episódios frequentes (com o algoritmo EMDO) e a descoberta de regras de episódios (com o algoritmo EMDO-P).\n\nResultados\nAs análises referentes ao EMDO foram focadas na influência do limite do suporte no número de episódios frequentes e tamanho em dados reais e sintéticos. A conclusão é que a poda com base na propriedade da anti-monotonicidade é muito efetiva em melhorar o tamanho do espaço de busca (e, consequentemente, o custo computacional).\nEm relação ao EMDO-P, ele tem um custo razoável, apesar de gastar mais memória. Além disso, ele é mais rápido, pois elimina os episódios irrelevantes.\n\n\nComparação\nEsse problema exato não é abordado em outros artigos, o que dificulta a comparação de resultados. Ainda assim, foi feita a comparação com algoritmos que trabalham com contextos diferentes, mas que conseguem encontrar os padrões. O EMDO foi o algoritmo que gerou menos candidatos e com padrões de regras mais ricas. Além disso, ele é o primeiro algoritmo que encontra padrões paralelos em sequências complexas, e encontra padrões não retornados por outros algoritmos."
  },
  {
    "objectID": "seminario1/artigo2.html#aplicações-e-desafios",
    "href": "seminario1/artigo2.html#aplicações-e-desafios",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "Aplicações e Desafios",
    "text": "Aplicações e Desafios\nAlgumas das possíveis aplicações para esses algortimos são:\n\nAnálise de Sistemas: Diversos sistemas modernos (como redes de computadores, de dispositivos IoT) podem aplicar a descoberta de padrões para otimizar seu funcionamento;\nAnálise de Comportamento: Logs de sistemas web, que são compostos de sequências de eventos complexas, podem ser analisados para otimizar a experência do usuário;\nAnálise de Varejo e Comportamento de Compra: A extração de regras pode ser utilizada para desenvolver estratégias de marketing baseadas em promoções ou recomendações.\n\nPorém, seu uso vem acompanhado de alguns desafios, principalmente quando se trata de análise de comportamento:\n\nVigilância e Privacidade: Com a disponibilidade de dados granulares e carimbados por timestamp, a possibilidade de rastreamento de atividades com más intenções é alta;\n\nUm exemplo é a vigilância de funcionários para aplicar punições;\n\nReforço de Viés: Ao aprender com dados históricos, que podem refletir preconceitos e desigualdades, o algoritmo reconhece esses padrões como “regras”;\nAcesso à Oportunidade: Criação de sistemas de pontuação para governar acesso a serviços essenciais:\n\nEmpresas de planos de saúde podem utilizar os dados para negar serviço ou cobrar mais de alguns clientes\n\n\nDe maneira geral, os algoritmos de descoberta de episódios paralelos frequentes têm diversas aplicações para melhorar os serviços, mas também um grande potencial para afetar, direta ou indiretamente, os usuários."
  },
  {
    "objectID": "seminario1/artigo2.html#execução",
    "href": "seminario1/artigo2.html#execução",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "Execução",
    "text": "Execução\nPara a execução do algoritmo, cada id dos datasets são considerados como um timestamp. Dessa forma, cada timestamp possui o conjunto de eventos. Os dados sintéticos são disponibilizados em um repositório no github, junto com a base de dados completa de algoritmos SPMF. Ela dsponibiliza diversos algoritmos, e a implementação está em Java (para qual o único pré-requisito é o jdx - java development kit). No arquivo .jar é possível escolher um algoritmo para rodar. No entanto, os algoritmos propostos no artigo não estão incluídos nesse repositório, e, após uma busca detalhada, não foi possível localizar suas implementações disponíveis publicamente online. Isso limitou a possibilidade de comparação direta com os métodos existentes na SPMF.\n\n\n\nSPMF\n\n\n\n\n\nSPMF"
  },
  {
    "objectID": "seminario1/artigo2.html#conclusão",
    "href": "seminario1/artigo2.html#conclusão",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "Conclusão",
    "text": "Conclusão\nO problema indicado no artigo, apesar de ser apresentado como algo inédito, é muito semelhante à mineração de padrões, se o timestamp for desconsiderado. Ao utilizar a definição de episódio paralelo, qualquer item em uma transação pode ser utilizado na contagem. Assim, os algoritmos EMDO e EMDO-P, apesar de mostrarem um bom funcionamento, não apresentam uma grande motivação para o seu uso. Além disso, a falta de disponibilidade do código fonte e diversos erros como falhas textuais, definições mal formadas e imagens incompletas comprometem reprodutibilidade dos experimentos e a compreensão dos resultados. Dessa forma, embora o artigo traga contribuições interessantes, ele peca na falta de uma fundamentação mais sólida e de uma apresentação mais cuidadosa para justificar a relevância dos algoritmos propostos."
  },
  {
    "objectID": "seminario1/artigo2.html#referências",
    "href": "seminario1/artigo2.html#referências",
    "title": "Artigo 2: Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences",
    "section": "Referências",
    "text": "Referências\n\nOuarem, O., Nouioua, F. & Fournier-Viger, P. Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences. Appl Intell 54, 701–721 (2024). https://doi.org/10.1007/s10489-023-05187-y"
  },
  {
    "objectID": "seminario1.html",
    "href": "seminario1.html",
    "title": "Introdução",
    "section": "",
    "text": "Os seminários da disciplina consistem em uma apresentação coletiva (da turma) de um artigo mais recente sobre tópicos diretamente relacionados ao conteúdo visto em sala. A ideia é que a turma como um todo estude os artigos mais recentes da área e discuta esses trabalhos em sala. Em cada sessão, discutimos dois artigos recentes relacionados aos tópicos abordados nas aulas teóricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canadá) – veja a proposta original em https://colinraffel.com/blog/role-playing-seminar.html. A proposta consiste em fazer uma encenação de papéis (role play) científicos para a apresentação do seminário. Nessa proposta, cada grupo cumprirá um papel na apresentação. Ao final, uma apresentação em formato de slides e um documento textual são produzidos. A apresentação é usada em sala de aula para fomentar as discussões, enquanto o documento fornece uma descrição textual das impressões da turma com a intenção de descrever o tema do artigo para um público amplo interessado em aprendizado de máquina e mineração de dados.\nSão apresentados a seguir os artigos discutidos no semestre 2025/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\nDifferentiable Pattern Set Mining\nJ. Fischer and J. Vreeken. 2021\nhttps://doi.org/10.1145/3447548.3467348\n\n\n\nDiscovering frequent parallel episodes in complex event sequences by counting distinct occurrences\nO. Ouarem, F. Nouioua, and P. Fournier-Viger. 2024\nhttps://doi.org/10.1007/s10489-023-05187-y"
  },
  {
    "objectID": "seminario1.html#artigo-1",
    "href": "seminario1.html#artigo-1",
    "title": "Introdução",
    "section": "",
    "text": "Differentiable Pattern Set Mining\nJ. Fischer and J. Vreeken. 2021\nhttps://doi.org/10.1145/3447548.3467348"
  },
  {
    "objectID": "seminario1.html#artigo-2",
    "href": "seminario1.html#artigo-2",
    "title": "Introdução",
    "section": "",
    "text": "Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences\nO. Ouarem, F. Nouioua, and P. Fournier-Viger. 2024\nhttps://doi.org/10.1007/s10489-023-05187-y"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizado Descritivo",
    "section": "",
    "text": "Aprendizado Descritivo (2025/1) — DCC/UFMG   Prof. Renato Vimieiro \n\nEssa disciplina é ofertada no Programa de Pós-Graduação em Ciência da Computação da Universidade Federal de Minas Gerais. Ela tem como objetivo apresentar técnicas avançadas para identificação de padrões descritivos em bases de dados. A(o) aluna(o) terá contato com técnicas para aprendizado de padrões não-supervisionados e supervisionados. Serão discutidas as dificuldades computacionais da busca por tais padrões, bem como sua utilidade para análise exploratória de dados.\nOs tópicos abordados na disciplina são:\n\nDiferenças entre aprendizado descritivo e preditivo.\nAprendizado descritivo não-supervisionado.\nAprendizado descritivo supervisionado.\nRepresentações condensadas.\nMétricas de qualidade de padrões descritivos.\nAlgoritmos de aprendizado de padrões descritivos supervisionados e não-supervisionados.\nEstudos de casos e aplicações em problemas reais.\n\nOs tópicos são apresentados através de aulas expositivas sobre o assunto, leitura e apresentação de seminários sobre artigos recentes na literatura, e projetos de aplicação dos métodos estudados para extração de conhecimento de bases de dados.\nUtilize o menu acima ou o link a seguir para visualizar o conteúdo produzido nos seminários e projetos desenvolvidos pelos alunos na oferta de 2025/1.\n\nSeminários: Padrões frequentes; Descoberta de subgrupos; Aplicações\n\nUma página similar também foi construída para ofertas anteriores do curso. Os links estão a seguir:\n\n2024/1."
  },
  {
    "objectID": "projetos.html",
    "href": "projetos.html",
    "title": "Projetos apresentados pelos alunos na disciplina Aprendizado Descritivo 2025/1",
    "section": "",
    "text": "O projeto da disciplina de Aprendizado Descritivo é uma atividade avaliativa conduzida pelos alunos da turma divididos em grupos. O objetivo do projeto é analisar um conjunto de dados escolhido pelo grupo, usando as técnicas vistas em sala de aula (aulas expositivas e seminários). Os links a seguir redirecionam para os repositórios dos respectivos projetos. É importante ressaltar que, embora tenha sido exigido rigor científico na execução do projeto, os resultados cumprem apenas um papel didático."
  },
  {
    "objectID": "projetos.html#tabela-de-projetos",
    "href": "projetos.html#tabela-de-projetos",
    "title": "Projetos apresentados pelos alunos na disciplina Aprendizado Descritivo 2025/1",
    "section": "Tabela de Projetos",
    "text": "Tabela de Projetos\n\n\n\nRelatório\nGitHub\nTítulo\nAutores\n\n\n\n\nPDF\nURL\n\nDaniel Schlickmann Bastos, Leonardo Caetano Gomide, Lucas Mesquita Andrade\n\n\nPDF\nURL\n\nArthur Codama, Caíque Fortunato, Fabio Marra, Victor Gabriel, Wesley Marques\n\n\nPDF\nURL\n\nAlexandre Cassimiro Silva Araújo, Diná Beatriz Xavier, Enilda Alves Coelho, Kael Soares Augusto, Mateus Reis Evangelista\n\n\nPDF\nURL\n\nGabriel Arcanjo Campelo Fadoul, Iasmin Correa Araujo, José Vinicius de Lima Massarico, Juan Marcos Braga Faria, Luiza Sodre Salgado\n\n\nPDF\nURL\n\nKênia Carolina Gonçalves\n\n\nPDF\nURL\n\nCaio Jorge Carvalho Lara, José Eduardo Duarte Massucato, Vinícius Leite Censi Faria\n\n\nPDF\nURL\n\nSamuel Henrique Miranda Alves\n\n\nPDF\nURL\n\nAlexis Duarte, Bernnardo Seraphim, Gabriel Castelo, Henrique Rotsen, Luisa Toledo\n\n\nPDF\nURL\n\nGuilherme Buxbaum Marinho Guerra, Lucas Xavier Veneroso, Marcelo Lommez Rodrigues de Jesus, Oluwatoyin Joy Omole, Samuel Kfuri Ferraz Marcussi\n\n\nPDF\nURL\n\nAmanda Mendes Pinho, Gabriel Tonioni Duarte, João Vítor Fernandes Dias, Larissa Duarte Santana"
  },
  {
    "objectID": "projetos.html#apresentações",
    "href": "projetos.html#apresentações",
    "title": "Projetos apresentados pelos alunos na disciplina Aprendizado Descritivo 2025/1",
    "section": "Apresentações",
    "text": "Apresentações\n\n\n\nData de Apresentação\nID\nIntegrantes\n\n\n\n\n03/07/2025\n1\nDaniel Schlickmann Bastos\n\n\n03/07/2025\n1\nLeonardo Caetano Gomide\n\n\n03/07/2025\n1\nLucas Mesquita Andrade\n\n\n03/07/2025\n7\nCaio Jorge Carvalho Lara\n\n\n03/07/2025\n7\nJosé Eduardo Duarte Massucato\n\n\n03/07/2025\n7\nVinícius Leite Censi Faria\n\n\n03/07/2025\n8\nSamuel Henrique Miranda Alves\n\n\n03/07/2025\n9\nAlexis Duarte\n\n\n03/07/2025\n9\nBernnardo Seraphim\n\n\n03/07/2025\n9\nGabriel Castelo\n\n\n03/07/2025\n9\nHenrique Rotsen\n\n\n03/07/2025\n9\nLuisa Toledo\n\n\n08/07/2025\n2\nArthur Codama\n\n\n08/07/2025\n2\nCaíque Fortunato\n\n\n08/07/2025\n2\nFabio Marra\n\n\n08/07/2025\n2\nVictor Gabriel\n\n\n08/07/2025\n2\nWesley Marques\n\n\n08/07/2025\n3\nAlexandre Cassimiro Silva Araújo\n\n\n08/07/2025\n3\nDiná Beatriz Xavier\n\n\n08/07/2025\n3\nEnilda Alves Coelho\n\n\n08/07/2025\n3\nKael Soares Augusto\n\n\n08/07/2025\n3\nMateus Reis Evangelista\n\n\n08/07/2025\n6\nKênia Carolina Gonçalves\n\n\n10/07/2025\n4\nGabriel Arcanjo Campelo Fadoul\n\n\n10/07/2025\n4\nIasmin Correa Araujo\n\n\n10/07/2025\n4\nJosé Vinicius de Lima Massarico\n\n\n10/07/2025\n4\nJuan Marcos Braga Faria\n\n\n10/07/2025\n4\nLuiza Sodre Salgado\n\n\n10/07/2025\n10\nGuilherme Buxbaum Marinho Guerra\n\n\n10/07/2025\n10\nLucas Xavier Veneroso\n\n\n10/07/2025\n10\nMarcelo Lommez Rodrigues de Jesus\n\n\n10/07/2025\n10\nOluwatoyin Joy Omole\n\n\n10/07/2025\n10\nSamuel Kfuri Ferraz Marcussi\n\n\n10/07/2025\n11\nAmanda Mendes Pinho\n\n\n10/07/2025\n11\nGabriel Tonioni Duarte\n\n\n10/07/2025\n11\nJoão Vítor Fernandes Dias\n\n\n10/07/2025\n11\nLarissa Duarte Santana"
  },
  {
    "objectID": "seminario1/artigo1.html",
    "href": "seminario1/artigo1.html",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "",
    "text": "Mineração de padrões é uma área de Aprendizado Descritivo que objetiva encontrar informações interpretáveis de grandes bancos de dados. Tal objetivo é alcançado por meio da mineração de “padrões” ou “regras” que definem conjuntos relevantes, seja em frequência ou em importância.\nAs aplicações de mineração de padrões são variadas, desde ciências naturais como Biologia e Química, estudos estatísticos e matemáticos e análises societais e comportamentais.\nInfelizmente, os algoritmos para mineração de padrões são extremamente custosos, sendo duplamente exponencial no número de atributos. Além disso, eles sofrem de redundância nas respostas, muitas vezes repetindo padrões similares e de relevância das respostas, sofrendo com overfitting ou underfitting."
  },
  {
    "objectID": "seminario1/artigo1.html#introdução-o-que-é-mineração-de-padrões",
    "href": "seminario1/artigo1.html#introdução-o-que-é-mineração-de-padrões",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "",
    "text": "Mineração de padrões é uma área de Aprendizado Descritivo que objetiva encontrar informações interpretáveis de grandes bancos de dados. Tal objetivo é alcançado por meio da mineração de “padrões” ou “regras” que definem conjuntos relevantes, seja em frequência ou em importância.\nAs aplicações de mineração de padrões são variadas, desde ciências naturais como Biologia e Química, estudos estatísticos e matemáticos e análises societais e comportamentais.\nInfelizmente, os algoritmos para mineração de padrões são extremamente custosos, sendo duplamente exponencial no número de atributos. Além disso, eles sofrem de redundância nas respostas, muitas vezes repetindo padrões similares e de relevância das respostas, sofrendo com overfitting ou underfitting."
  },
  {
    "objectID": "seminario1/artigo1.html#binaps",
    "href": "seminario1/artigo1.html#binaps",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "2 BinaPs",
    "text": "2 BinaPs\nPara resolver a problemática acima, o algoritmo introduz o BinaPs, uma solução que vê o problema por meio da lente de aprendizado de máquina ao invés de construção de conjuntos. Para entender melhor as duas perspectivas, considere as diferenças principais do BinaPs para algoritmos tradicionais:\n\nApriori, Eclat, FP-Growth:\n\nPadrões escolhidos por frequência\nPadrões redundantes encontrados\nApenas otimizados por heurísticas\nCalculado na CPU\n\nBinaPs:\n\nFunções diferenciáveis para descoberta de padrões\nPadrões menos redundantes\nGPU para cálculos\nSignificativamente mais escalável\nOtimizável por parâmetros de entrada como learning rate\n\n\n\n2.1 Funcionamento\nInspirado por decoders e encoders, o algoritmo tem como objetivo obter os atributos de um item, codificar eles em o mesmo número ou menos de neurônios no processo e retornar para o número inicial como representado pela Figura 1.\n\n\n\nFigura 1: Encoder e Decoder - Fonte: o autor\n\n\n\n\n\n\nO BinaPs contém algumas otimizações e considerações quando considerado com outras rede neurais, dentre elas:\n\nOs neurônios e pesos finais são binários \\(\\{0, 1\\}\\)\nViés é usado para evitar overfitting\nNormalização da função de perda para evitar saídas de apenas \\(\\{1\\}\\) ou \\(\\{0\\}\\) em bases densas e esparsas.\nGated Straight-Through Estimator para não penalizar os neurônios desligados\n\nApós essas mudanças, o algoritmo funciona como descrito pela Figura 2.\n\n\n\nFigura 2: Funcionamento do BinaPs 1\n\n\n\n\n\n\n\n\n2.2 Experimentos\nO BinaPs foi comparado com três outros competidores na área de mineração de dados: Asso, Slim e Desc, que usam matrizes booleanas, mineração de conjuntos por MDL e maximum entropy modeling respectivamente. Os experimentos foram divididos em duas categorias: sintéticos e reais.\n\n2.2.1 Sintéticos\nDados sintéticos foram escolhidos pois é possível inserir ou estudar padrões reais nos dados previamente, podendo assim comparar os resultados dos algoritmos com o “ground truth”, ou seja, o que assumimos ser a verdade.\nPara medir a performance dos algoritmos foi usado a F1-score, uma medida calculada pela média harmônica do precision e do recall, comumente usada em aprendizado de máquina para avaliar a performance de modelos.\n\n2.2.1.1 Escalabilidade\n\n\n\nFigura 3: Estatísticas BinaPs, Asso, Slim e Desc: Features 2\n\n\n\n\n\n\n\n(a) Features: F1-Score\n\n\n\n\n\n\n\n\n\n\n\n(b) Features: Time in Seconds\n\n\n\n\n\n\n\n\n\n\n\nCom um número crescente de features (atributos), o BinaPs se mostra mais preciso (Figura 3 (a)) e menos custoso (Figura 3 (b)) em tempo que os outros três, com o Asso se assemelhando a ele em resultados, mas não em performance, eventualmente não sendo capaz de rodar datasets maiores.\n\n\n2.2.1.2 Resistência a ruídos\nMuitas vezes dados reais possuem ruídos, seja de medidas errôneas, problemas no dataset ou imprevisibilidade dos dados. Para testar se os algoritmos são resistentes a tais cenários foram inseridos quantidades crescentes de ruídos nos databases testados com os seguintes resultados:\n\n\n\nFigura 4: Estatísticas BinaPs, Asso, Slim e Desc: Ruídos 3\n\n\n\n\n\n\n\n(a) Ruídos: F1-Score\n\n\n\n\n\n\n\n\n\n\n\n(b) Ruídos: Time in Seconds\n\n\n\n\n\n\n\n\n\n\n\nAo analisar os gráficos, ambos o BinaPs e o Asso são resistentes a ruídos em ambos F1-score (Figura 4 (a)) e tempo de execução (Figura 4 (b)). Já ambos Slim e Desc são afetados por ruídos no F1-score (Figura 4 (a)) e o Slim em tempo de execução (Figura 4 (b)) também.\n\n\n2.2.1.3 Operabilidade com Samples\n\n\n\nFigura 5: F1-Score \\(\\times\\) Samples 4\n\n\n\n\n\n\nPara testar a capacidade do BinaPs de operar com poucos samples, também foi feito testes com quantidades crescentes de dados para ver sua performance.\nMesmo com um número bem reduzido de samples o BinaPs foi capaz de conseguir uma pontuação boa (Figura 5), melhorando marginalmente com mais samples até estabilizar perto do final do gráfico.\n\n\n\n2.2.2 Reais\nForam usados 5 bases de dados reais para o comparativo entre os algoritmos:\n\nDNA: Dados de amplificação de DNA\nAccidents: Dados de acidentes belgas\nInstacart: Dados de compras de supermercado online\nKorsarak: Dados de cliques em um site de notícias hungaro\nGenomes: Dados de indivíduos no projeto 1000 genomes\n\n\n2.2.2.1 Análise Qualitativa\nAo contrário dos dados sintéticos, não temos como saber quais padrões são “corretos” ou “incorretos”. Dessa forma, a análise é mais subjetiva. Primeiro comparamos o número de padrões encontrados (Tabela 1 (b)) nos 5 bancos de dados (Tabela 1) e o tempo de execução de cada algoritmo (Tabela 1 (c)).\n\n\n\nTabela 1: Tabela comparativa dos datasets 5\n\n\n\n\n\n\n\n(a) Linhas e colunas dos datasets\n\n\n\n\n\n\\(Dataset\\)\n\\(\\#\\ rows\\)\n\\(\\#\\ cols\\)\n\n\n\n\nDNA\n\\(2458\\)\n\\(391\\)\n\n\nAccidents\n\\(340183\\)\n\\(468\\)\n\n\nInstacart\n\\(2704831\\)\n\\(1235\\)\n\n\nKosarak\n\\(990002\\)\n\\(41270\\)\n\n\nGenomes\n\\(2504\\)\n\\(226623\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) Número de padrões encontrados\n\n\n\n\n\n\\(Asso\\)\n\\(BinaPs\\)\n\\(Desc\\)\n\\(Slim\\)\n\n\n\n\n\\(134\\)\n\\(131\\)\n\\(345\\)\n\\(281\\)\n\n\n\\(133\\)\n\\(78\\)\n\\(215\\)\n\\(12261\\)\n\n\n\\(n/a\\)\n\\(328\\)\n\\(712\\)\n\\(8119\\)\n\n\n\\(n/a\\)\n\\(302\\)\n\\(n/a\\)\n\\(n/a\\)\n\n\n\\(n/a\\)\n\\(42\\)\n\\(n/a\\)\n\\(n/a\\)\n\n\n\n\n\n\n\n\n\n\n\n(c) Comparativo de tempo\n\n\n\n\n\n\\(Asso\\)\n\\(BinaPs\\)\n\\(Desc\\)\n\\(Slim\\)\n\n\n\n\n\\(4 m\\)\n\\(26 s\\)\n\\(20 s\\)\n\\(2 s\\)\n\n\n\\(12 h\\)\n\\(6 m\\)\n\\(14 m\\)\n\\(21 h\\)\n\n\n\\(\\infty\\)\n\\(44 m\\)\n\\(25 m\\)\n\\(8 h\\)\n\n\n\\(\\infty\\)\n\\(5 h\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\n\n\\(\\infty\\)\n\\(9 m\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\n\n\n\n\n\n\n\n\n\n\nEm alguns casos, os outros algoritmos não conseguiram rodar em até 3 dias ou com 256GB de RAM. Tais cenários foram marcados com \\(n/a\\) ou \\(\\infty\\) (Tabela 1 (b)).\nO BinaPs retornou resultados menos redundantes, facilitando interpretabilidade. Além disso, foram notados algumas falhas em outros algoritmos, dentre eles:\n\nAsso não conseguiu escalar bem\nSlim encontrou milhares de resultados redundantes\nDesc sofre de underfitting e só retornou padrões de tamanho 2 no Instacart.\n\n\n\n2.2.2.2 Análise Quantitativa\nFoi feita uma análise quantitativa em 3 dos bancos de dados listados acima. Duas comparativas (DNA, Instacart) e uma individual.\nDNA: BinaPs e Asso encontraram blocos de DNA e conjuntos desses blocos como estruturas, representando elementos biologicamente relevantes. Slim começa a encontrar blocos, mas faz um overfitting para padrões grandes demais que acontecem raramente e não tem estrutura evidente de blocos. Desc encontra padrões pequenos apenas graças a um underfitting.\nInstacart: BinaPs encontra padrões grandes com combinações arbitrárias como um conjunto de 12 frutas comprados de formas diferentes. O Slim quebra este conjunto em milhares de padrões menores. Desc faz underfitting novamente, encontrando padrões de tamanho 2 apenas. Além disso, o BinaPs também encontrou padrões pequenos que se assemelham à lista de ingredientes de pratos culinários, mostrando relevância novamente.\nGenomes: De acordo com os autores, esta seção obteve os resultados mais promissores, sendo um motivador principal para o estudo.\nFoi possível encontrar padrões antes conhecidos de genes relacionados, como os NUCB2 e ABCC8 relacionados à diabetes tipo 2 e pressão alta em populações japonesas. Porém, muitas vezes esses grupos conhecidos estavam adjuntos a outros elementos, como o NCR3LG1 e ROMO1. Isso demonstra a possibilidade do uso do algoritmo para estabelecer relações novas que podem ser estudadas no futuro.\nOutro exemplo foi o dos genes SF3A1, RRP7A e Z82190 onde os dois primeiros codificam proteínas que são parte do ribossomo (que por sua conta é a fábrica de proteínas da célula), já o terceiro não é caracterizado. O padrão destes juntos é uma dica que pode guiar estudos futuros nessa área.\nPor final, ao analisar padrões de variantes entre alelos, o BinaPs sugere que variantes raras normalmente acompanhadas de comuns podem acontecer de um para o outro “\\(0 \\mid 1\\)” como na literatura, mas muitas vezes também acontece em “\\(1 \\mid 0\\)”, ou seja, os raros no alelo que antes havia comuns e vice-versa. Os autores não sabem se isso têm significado biológico, sugerindo que isso seja analisado por profissionais da área.\n\n\n\n\n2.3 Execução\nO artigo nos entrega um Link para o repositório. Para rodar o BinaPs em uma máquina comum é necessário:\n\n2.3.1 Gerar dados sintéticos\n\nBaixar e descompactar os arquivos\nInstalar as dependências (Pytorch, Scipy, Pandas, Numpy, R)\nAlterar arquivo genSynth.sh para parâmetros de uma máquina convencional (8 a 32GB de RAM)\nExecutar ./genSynth.sh\n\nO resultado é um arquivo .dat com os dados em formato de matriz binária esparsa. Ou seja, para cada linha, os elementos da linha são os indices das posições com valor 1 na matriz original.\n\n2.3.1.1 Executar o algoritmo\nPara executar basta chamar python main.py --input &lt;arquivo.dat&gt; --batch_size &lt;32 ou 64&gt; que pode também ser adjunto dos parâmetros apresentados na Tabela 2.\n\n\n\nTabela 2: Parâmetros do BinaPs 6\n\n\n\n\n\n\n\n\n\n\n\nParâmetro\nTipo\nValor padrão\nDescrição\n\n\n\n\n--save_model\nbool\n\\(False\\)\nSe ativado, salva o modelo treinado para disco\n\n\n--gamma\nfloat\n\\(0.1\\)\nFator de decaimento do learning rate (usado no agendador de LR)\n\n\n--lr\nfloat\n\\(0.01\\)\nTaxa de aprendizado (learning rate)\n\n\n--train_set_size\nfloat\n\\(0.9\\)\nProporção dos dados usada para treinamento\n\n\n--weight_decay\nfloat\n\\(0.0\\)\nFator de penalização L2 (regularização dos pesos)\n\n\n--batch_size\nint\n\\(64\\)\nTamanho do batch para treinamento\n\n\n--epochs\nint\n\\(10\\)\nNúmero de épocas de treinamento\n\n\n--hidden_dim\nint\n\\(-1\\)\nNúmero de neurônios ocultos (usa #features se -1)\n\n\n--log_interval\nint\n\\(10\\)\nIntervalo (em batches) para exibir logs de treino\n\n\n--seed\nint\n\\(1\\)\nSemente para reprodutibilidade (random seed)\n\n\n--test_batch_size\nint\n\\(64\\)\nTamanho do batch para teste\n\n\n--thread_num\nint\n\\(16\\)\nNúmero de threads a serem usadas no treinamento\n\n\n--input (-i)\nstr\nObrigatório\nCaminho para o arquivo de entrada (dados usados para treino e teste)\n\n\n\n\n\n\n\n\n2.3.1.2 Saída do algoritmo\nApós o treinamento marcado pelas “Epoch” temos alguns dados como a “Average loss” e a “Accuracy” seguido dos padrões dispostos na Figura 6.\n\n\n\nFigura 6: Resultado da execução do BinaPs 7\n\n\n\n\n\n\nCada linha dos padrões mostra um padrão que foi reconstruído, como por exemplo o \\([45, 46, 47, 48, 49]\\) seguido de dois números: O primeiro o número de amostras que ativaram todos os bits e o segundo amostras que ativaram metade dos bits do padrão. Ou seja, \\(4404\\) vezes os bits \\(45\\) a \\(49\\) foram completamente ativados e \\(4425\\) vezes parcialmente ativados (metade).\nConclusão: O padrão \\([45-49]\\) é altamente confiável pois aparece em mais de 99% das vezes que é parcialmente ativado, indicando forte consistência local nos dados.\n\n\n\n\n2.4 Impacto Social\n\n2.4.1 Transparência e Justiça\nO método do BinaPs é significativamente mais interpretável que outras soluções usando inteligência artificial ou caixas-pretas. Tal transparência entrega um grau de confiança maior aos resultados e pode levar a estudos e entendimentos novos relacionados à area investigada.\nAlém disso, como o processo é transparente, ele se torna mais fácil de ser ajustado por profissionais para evitar vieses indesejados como os de cor, gênero, raça, classe e outros.\n\n\n2.4.2 Cenários de Uso\nSimilarmente a outros métodos de mineração de padrões, os usos são bem vastos, mas dessa vez eles são beneficiados também pela transparência. Aqui estão alguns deles:\n\nSaúde\n\nEstudo de biomarcadores relevantes para diagnósticos\nDetecção de padrões comuns à doenças como sintomas\n\nCidades inteligentes\n\nAnálise de padrões de tráfego para otimização do transporte\nMineração de padrões no uso de serviços públicos\n\nEducação\n\nAnálise de trajetórias acadêmicas para politicas de incentivo\nEstudo de consumo de cursos para personalização de trilhas\n\nComércio\n\nPadrões de compras para sistemas de recomendação\nPerfis de consumidores para marketing personalizado\n\nGovernos e Organizações\n\nDetecção de padrões de fraude em transações como as bancárias\nEstudo de padrões comportamentais para prevenção de crimes\n\n\n\n\n2.4.3 Riscos\nO BinaPs é uma ferramenta. Da mesma forma que é necessário cuidado ao usar um martelo, é importante saber os riscos que tomamos ao usar uma ferramenta dessas para evitar problemas. Um dos maiores riscos são os de dados enviesados.\nGrande porção dos dados usados são daqueles que mais coletam dados, que tendem a ser países de primeiro mundo nas classes media e alta. Além disso, muitos dados são enviesados por cor, raça, gênero e outros fatores que não devem serem analisados como causalidade por motivos éticos.\nExemplos de dados enviesados incluem a ferramenta de triagem de currículos da Amazon, que aprendeu e manteve o preconceito de gênero que estava presente antes de sua implementação, o que desfavoreceu o gênero feminino.\nAlém disso, há áreas de implementação que não podem ter vieses como por exemplo:\n\nConcessão de crédito\n\nDiscriminação, Desinformação, Privacidade, Over-Marketing\n\nPrecificação de seguros e planos de saúde\n\nDiferenciação de grupos por fatores pessoais, étnicos, etários ou de doenças.\n\n\nEm ambos os casos, são necessárias políticas como a LGPD para garantir a anonimização dos dados e a publicação de métodos e entradas utilizados para que especialistas possam discutir as questões éticas do uso dos dados específicos utilizados."
  },
  {
    "objectID": "seminario1/artigo1.html#conclusão",
    "href": "seminario1/artigo1.html#conclusão",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "3 Conclusão",
    "text": "3 Conclusão\nO BinaPs é um algoritmo de mineração de padrões inovador, com características transparentes e eficientes em relação à competição. Seu código é aberto e bem explicado com um gerador de dados sintéticos incluso e alguns estudos preliminares de áreas que podem beneficiar do seu uso. Se for usado como uma ferramenta de forma responsável, ele pode ser um pioneiro em estudos, análises e sumarizações de dados massivos."
  },
  {
    "objectID": "seminario1/artigo1.html#links-de-interesse",
    "href": "seminario1/artigo1.html#links-de-interesse",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "4 Links de Interesse",
    "text": "4 Links de Interesse\n\nTítulo: Differentiable Pattern Set Mining - Fischer e Vreeken (2021)\nArtigo: DOI, PDF, MP4 (Apresentação dos Autores)"
  },
  {
    "objectID": "seminario1/artigo1.html#referências",
    "href": "seminario1/artigo1.html#referências",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "5 Referências",
    "text": "5 Referências\n\n\nFischer, Jonas, e Jilles Vreeken. 2021. “Differentiable Pattern Set Mining”. Em Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 383–92. KDD ’21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3447548.3467348."
  },
  {
    "objectID": "seminario1/artigo1.html#footnotes",
    "href": "seminario1/artigo1.html#footnotes",
    "title": "Artigo 1: Differentiable Pattern Set Mining",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\npor Fischer e Vreeken (2021) sob a licensa CC BY 4.0.↩︎\npor Fischer e Vreeken (2021) sob a licensa CC BY 4.0.↩︎\npor Fischer e Vreeken (2021) sob a licensa CC BY 4.0.↩︎\npor Fischer e Vreeken (2021) sob a licensa CC BY 4.0.↩︎\npor Fischer e Vreeken (2021) sob a licensa CC BY 4.0.↩︎\nFonte: grupo hacker.↩︎\nFonte: grupo hacker.↩︎"
  },
  {
    "objectID": "seminario2.html",
    "href": "seminario2.html",
    "title": "Introdução",
    "section": "",
    "text": "Os seminários da disciplina consistem em uma apresentação coletiva (da turma) de um artigo mais recente sobre tópicos diretamente relacionados ao conteúdo visto em sala. A ideia é que a turma como um todo estude os artigos mais recentes da área e discuta esses trabalhos em sala. Em cada sessão, discutimos dois artigos recentes relacionados aos tópicos abordados nas aulas teóricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canadá) – veja aqui a proposta original. A proposta consiste em fazer uma encenação de papéis (role play) científicos para a apresentação do seminário. Nessa proposta, cada grupo cumprirá um papel na apresentação. Ao final, uma apresentação em formato de slides e um documento textual são produzidos. A apresentação é usada em sala de aula para fomentar as discussões, enquanto o documento fornece uma descrição textual das impressões da turma com a intenção de descrever o tema do artigo para um público amplo interessado em aprendizado de máquina e mineração de dados.\nSão apresentados a seguir os artigos discutidos no semestre 2025/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\n\nFinding interpretable class-specific patterns through efficient neural search\nAutores: N. P. Walter; J. Fischer; J. Vreeken. 2024\nDOI: 10.1609/aaai.v38i8.28756\n\n\n\n\n\nLocal Subgroup Discovery on Attributed Network Graphs\nAutores: C. V. Heinrich; T. Lombarts; J. Mallens; L. Tortike; D. Wolf; W. Duivesteijn. 2025\nDOI: 10.1007/978-3-031-91398-3_15"
  },
  {
    "objectID": "seminario2.html#artigo-3seminario_art3",
    "href": "seminario2.html#artigo-3seminario_art3",
    "title": "Introdução",
    "section": "",
    "text": "Finding interpretable class-specific patterns through efficient neural search\nAutores: N. P. Walter; J. Fischer; J. Vreeken. 2024\nDOI: 10.1609/aaai.v38i8.28756"
  },
  {
    "objectID": "seminario2.html#artigo-4seminario_art4",
    "href": "seminario2.html#artigo-4seminario_art4",
    "title": "Introdução",
    "section": "",
    "text": "Local Subgroup Discovery on Attributed Network Graphs\nAutores: C. V. Heinrich; T. Lombarts; J. Mallens; L. Tortike; D. Wolf; W. Duivesteijn. 2025\nDOI: 10.1007/978-3-031-91398-3_15"
  },
  {
    "objectID": "seminario2/artigo4.html",
    "href": "seminario2/artigo4.html",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "",
    "text": "Atualmente, vivemos cercados por uma quantidade muito grande de dados sendo gerada o tempo todo, especialmente em redes sociais, biológicas e de comunicação. Nesse cenário, tornou-se essencial usar algoritmos que consigam identificar, automaticamente, grupos que se comportam de maneira diferente do que é mais comum nessas redes. Essas redes (ou grafos) representam entidades (como pessoas, sites, itens) como nós e as conexões entre elas como arestas.\nUma das formas de explorar esses padrões especiais nessas redes é com a técnica do Subgroup Discovery (SD), ou descoberta de subgrupos. Imagine, por exemplo, que você queira encontrar uma turma de alunos particularmente altos em uma escola. O SD faria isso comparando a altura média dessa turma com a altura média de todos os alunos da escola.\nO problema é que, em redes muito grandes e diversas, comparar um grupo com o todo pode acabar escondendo padrões importantes em um contexto local. Na analogia, um aluno do ensino fundamental pode ser muito alto para a idade dele, mas isso pode passar despercebido se a comparação for com alunos de toda escola, que inclui os alunos do ensino médio, que naturalmente são maiores. É justamente para lidar com isso que surge o Local Subgroup Discovery (LSD). Ao invés de comparar um grupo com toda a rede, ele o compara apenas com um grupo de referência local, ou seja, com outros nós parecidos naquele contexto local.\nEste artigo inovou ao aplicar esse conceito em redes com atributos, onde cada nó possui características associadas (como uma pessoa, que possui nome, idade, altura, etc). A ideia aqui é usar essas características combinadas com a estrutura da rede para encontrar grupos que realmente se destacam, seja por comportamento, perfil ou outro critério interessante."
  },
  {
    "objectID": "seminario2/artigo4.html#introdução",
    "href": "seminario2/artigo4.html#introdução",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "",
    "text": "Atualmente, vivemos cercados por uma quantidade muito grande de dados sendo gerada o tempo todo, especialmente em redes sociais, biológicas e de comunicação. Nesse cenário, tornou-se essencial usar algoritmos que consigam identificar, automaticamente, grupos que se comportam de maneira diferente do que é mais comum nessas redes. Essas redes (ou grafos) representam entidades (como pessoas, sites, itens) como nós e as conexões entre elas como arestas.\nUma das formas de explorar esses padrões especiais nessas redes é com a técnica do Subgroup Discovery (SD), ou descoberta de subgrupos. Imagine, por exemplo, que você queira encontrar uma turma de alunos particularmente altos em uma escola. O SD faria isso comparando a altura média dessa turma com a altura média de todos os alunos da escola.\nO problema é que, em redes muito grandes e diversas, comparar um grupo com o todo pode acabar escondendo padrões importantes em um contexto local. Na analogia, um aluno do ensino fundamental pode ser muito alto para a idade dele, mas isso pode passar despercebido se a comparação for com alunos de toda escola, que inclui os alunos do ensino médio, que naturalmente são maiores. É justamente para lidar com isso que surge o Local Subgroup Discovery (LSD). Ao invés de comparar um grupo com toda a rede, ele o compara apenas com um grupo de referência local, ou seja, com outros nós parecidos naquele contexto local.\nEste artigo inovou ao aplicar esse conceito em redes com atributos, onde cada nó possui características associadas (como uma pessoa, que possui nome, idade, altura, etc). A ideia aqui é usar essas características combinadas com a estrutura da rede para encontrar grupos que realmente se destacam, seja por comportamento, perfil ou outro critério interessante."
  },
  {
    "objectID": "seminario2/artigo4.html#funcionamento-do-método",
    "href": "seminario2/artigo4.html#funcionamento-do-método",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Funcionamento do método",
    "text": "Funcionamento do método\nComo mencionado anteriormente, o método proposto pelos autores combina a estrutura da rede com os atributos para encontrar um grupo de referência que se destaque da rede geral e, dentro dele, um grupo local que se destaque.\n\n\n\nEstrutura retornada pelo método\n\n\nVamos quebrar o processo em partes:\n\nEscolhe-se um protótipo, que é um ponto de partida do método, podendo ser qualquer ponto da rede.\nUtilizando procedimentos de caminho mínimo (como Dijkstra), calcula-se a distância entre esse protótipo e os demais pontos da rede, criando um ranking.\nCria-se o subgrupo de referência (os ρ pontos mais próximos do protótipo) e o subgrupo local (os σ pontos mais próximos do protótipo, dentro de ρ), de forma que a medida de qualidade seja maximizada.\nAvalia-se o quão diferente o subgrupo local é do grupo de referência, com base na distribuição da variável-alvo. Para medir essa diferença, os autores utilizaram uma métrica da teoria da informação chamada Divergência Ponderada de Kullback-Leibler (WKL), que basicamente mede o quanto as distribuições se diferem.\n\n\n\n\nExecução do método a partir do protótipo\n\n\n\nEmpate nas distâncias\nVocê pode ter muito bem observado que simplesmente usar o algoritmo de caminho mínimo pode gerar empates: muitos pontos podem estar a uma exata mesma distância, em nível de aresta, do protótipo. É aqui que entra a Distância de Gower, que considera os atributos dos nós para desempatar. Logo, nós que são mais parecidos com o protótipo são preferidos em relação aos outros, garantindo que o grupo formado tenha sentido tanto na estrutura quanto nas características. No exemplo abaixo, tínhamos um empate, a nível de aresta, entre o protótipo e os outros nós, mas as características dos mesmos foi usada para desempatar, produzindo este ranking.\n\n\n\nRanking dos nós mais próximos ao protótipo\n\n\n\n\nPós-processamento dos grupos\nAo selecionarmos vários protótipos, pode acontecer de alguns deles serem muito próximos na rede, o suficiente para gerar subgrupos muito parecidos. Pensando nisso, os autores fazem um pós-processamento dos grupos encontrados, utilizando o coeficiente de Dice-Sørensen, que basicamente diz o quanto dois grupos se sobrepõem.\n\n\n\nSobreposição dos subgrupos de protótipos próximos\n\n\nDefinimos um limiar de sobreposição. Ao encontrarmos um par de grupos que se sobrepõem demais, cortamos um deles, o que garante que, ao final, tenhamos subgrupos especiais suficientemente diferentes."
  },
  {
    "objectID": "seminario2/artigo4.html#bases-de-dados-de-teste",
    "href": "seminario2/artigo4.html#bases-de-dados-de-teste",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Bases de dados de teste",
    "text": "Bases de dados de teste\nA proposta foi testada em três conjuntos de dados distintos:\n\nOGBG-MolPCBA: conjunto com 41.127 grafos. Cada grafo é uma molécula, onde os nós são os átomos, com atributos como número atômico, hibridização, etc. A descoberta de subgrupos ajuda a identificar estruturas químicas com propriedades especiais.\nTwitch PT: rede de streamers portugueses da plataforma Twitch. Trata-se de um conjunto de 1.912 nós, que representam streamers, e 64.510 arestas, que representam seguidores. A variável-alvo é o uso de linguagem explícita. O LSD encontrou subgrupos locais de streamers que não usam linguagem explícita, mesmo estando cercados por quem usa.\nWebKB Cornell: rede de páginas da web da Universidade Cornell, onde cada nó é uma página com atributos de texto (foram 1703 atributos por nó). O LSD descobriu subgrupos de páginas com temas administrativos dentro de contextos predominantemente acadêmicos.\n\nEssas bases de dados são grandes o suficiente para provar a escalabilidade do método e a veracidade das evidências, mas não grandes demais para se tornar computacionalmente custoso."
  },
  {
    "objectID": "seminario2/artigo4.html#resultados-e-benefícios",
    "href": "seminario2/artigo4.html#resultados-e-benefícios",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Resultados e benefícios",
    "text": "Resultados e benefícios\nPara avaliar a importância do uso de grupos de referência locais, os autores realizaram um “ablation study” substituindo o grupo de referência por toda a rede, conforme a abordagem tradicional do SD. Essa comparação direta permite verificar o impacto do aspecto local no processo de descoberta de subgrupos.\nPara entendermos a tabela abaixo, vamos explicar alguns conceitos importantes:\n\nWRAcc: mede o quão bem o subgrupo se diferencia do restante da rede em relação à variável-alvo. Quanto maior, mais informativo é o subgrupo.\nCobertura t(v)=1: indica a porcentagem dos nós com valor positivo para o alvo (por exemplo, linguagem explícita) que estão incluídos no subgrupo.\nOverlap: mostra o quanto os subgrupos encontrados por LSD e SD se parecem. Valores baixos indicam que os métodos descobrem grupos bem diferentes.\n\n\n\n\n\n\n\n\n\n\n\nDataset\nMétodo\nOverlap com LSD\nWRAcc\nCobertura t(v)=1\n\n\n\n\nOGBG-MolPCBA\nLSD\n—\n0.215\n31.56%\n\n\n\nSD\n0.0%\n0.0533\n0.00%\n\n\nTwitch PT\nLSD\n—\n0.2349\n28.30%\n\n\n\nSD\n0.62%\n0.0798\n63.84%\n\n\nWebKB Cornell\nLSD\n—\n0.2211\n81.00%\n\n\n\nSD\n8.99%\n0.1103\n48.60%\n\n\n\nOs resultados revelam que a abordagem local (LSD) supera consistentemente o SD tradicional em termos de qualidade dos subgrupos. A métrica WRAcc, usada para medir o poder discriminativo, é significativamente maior nos subgrupos gerados pelo LSD. Além disso, subgrupos descobertos são substancialmente diferentes (com overlap inferior a 10%) e capturam uma maior proporção dos nós com a variável-alvo positiva em dois dos três conjuntos de dados.\nEsses achados reforçam a tese central do artigo: ao considerar o contexto local dos nós, tanto em termos de estrutura da rede quanto de atributos, conseguimos identificar padrões mais informativos, que se perderiam se olhássemos apenas para o comportamento global da rede."
  },
  {
    "objectID": "seminario2/artigo4.html#aplicações-e-impactos-sociais",
    "href": "seminario2/artigo4.html#aplicações-e-impactos-sociais",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Aplicações e impactos sociais",
    "text": "Aplicações e impactos sociais\nComo mencionado anteriormente, esse método pode ser utilizado em diferentes aplicações, como na biologia molecular, redes sociais, organização da informação e na detecção de fraudes e anomalias. Além disso, pode ser usado em cenários de cibersegurança, detecção de grupos radicais e de desinformação, segmentação de clientes, etc. Entretanto, o uso desse método sem o devido tratamento e supervisão pode desencadear alguns problemas:\n\nInvasão de privacidade: mesmo se os dados estiverem anonimizados, o contexto local em que o nó está inserido pode revelar quem é o indivíduo. Em redes sociais, por exemplo, o padrão de interação de um usuário e as características associadas ao seu perfil podem ser suficientes para identificá-lo.\nDiscriminação algorítmica: atributos como raça, gênero ou status socioeconômico podem estar embutidos nos dados de entrada e o LSD pode retornar subgrupos “anômalos” que, na prática, são grupos historicamente marginalizados, o que pode ser usado de maneira tendenciosa.\nDesigualdade no acesso ou no tratamento: subgrupos identificados como “exceções” podem ser tratados de forma desigual por sistemas automáticos. Por exemplo, em serviços sociais, famílias com perfis atípicos em relação à vizinhança podem ser preteridas ou até ignoradas.\n\nAlém dessas questões, o algoritmo apresenta limitações inerentes ao problema que ele busca solucionar. Um deles é o fato de que um subgrupo pequeno pode implicar diretamente seus membros. Imagine, por exemplo, um fórum de mães de primeira viagem, no qual um grupo pequeno começa a postar com mais frequência sobre ansiedade pós-parto. O sistema pode rotular esse grupo como “de risco”, mesmo que esteja buscando apoio, o que pode levar a bloqueios, alertas automáticos ou vigilância desnecessária.\nTudo isso denota a importância de adotar boas práticas no uso do método. Critérios éticos e transparentes devem ser estabelecidos e seguidos antes de utilizar o método, com uma supervisão humana e com contextualização adequada dos resultados. A implementação de salvaguardas contra o uso indevido, manipulação dos resultados deve ser também adotada."
  },
  {
    "objectID": "seminario2/artigo4.html#como-executar-o-método-na-prática",
    "href": "seminario2/artigo4.html#como-executar-o-método-na-prática",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Como executar o método na prática",
    "text": "Como executar o método na prática\nVocê também pode executar este método na sua própria máquina! Para isso, basta acessar o seguinte repositório no GitHub: https://github.com/TUeEMM/LSD-ATNG. Os códigos foram implementados em Python e os arquivos .ipynb (notebooks Jupyter) presentes no repositório contêm a execução completa do método feita pelos próprios autores, com os dados das bases mencionadas anteriormente. Você pode simplesmente visualizar os resultados ou adaptar os scripts para os seus próprios dados.\nA função principal que executa o método se chama find_groups, localizada no arquivo methods.py. Ela recebe os parâmetros:\n\nG: o grafo (estrutura da rede, em formato compatível com a biblioteca networkx)\nk: quantidade de subgrupos desejados\nlu: uma tabela pandas.DataFrame contendo os atributos dos nós\nablation_mode: se True, executa o método sem considerar grupos de referência locais (simula o SD tradicional). Por padrão, é passado como False\nuse_multiprocessing: se True, utiliza múltiplos núcleos para acelerar o processo. Por padrão, é passado como True\n\nAbaixo, mostramos um exemplo de execução do início ao fim, incluindo os resultados e os recursos computacionais utilizados. Esse exemplo foi realizado no Google Colab, mas você pode adaptá-lo facilmente para qualquer ambiente com Python instalado.\n\nImportante: para rodar o método, é necessário que você tenha um grafo (networkx.Graph) representando sua rede e uma tabela (pandas.DataFrame) com os atributos dos nós e uma variável-alvo binária (0 ou 1)\n\n\nClonando o repositório: o primeiro passo é clonar o repositório ou baixar o código-fonte do projeto.\ngit clone https://github.com/TUeEMM/LSD-ATNG.git\nCriando o grafo: nesse exemplo, usamos o nosso grafo. No seu caso, substitua pelo seu próprio grafo, construído com a biblioteca networkx.\nimport networkx\n\nedge_index = data.edge_index # Extrai a matriz de arestas dos dados\nnum_nodes = data.num_nodes # Obtém o número total de nós presentes no grafo\nG = nx.Graph() # Cria um novo grafo não direcionado\n\n# Adiciona todos os nós ao grafo, que são numerados de 0 a num_nodes - 1\nG.add_nodes_from(range(num_nodes))\n\n# Converte os índices das arestas em uma lista de tuplas (u, v), onde u e v\n# são os nós que compõem a aresta\nedges = list(zip(edge_index[0].tolist(), edge_index[1].tolist()))\n\nG.add_edges_from(edges) # Adiciona as arestas ao grafo\nCriando a tabela de atributos: construímos uma tabela contendo os atributos dos nós e o rótulo binário. Novamente, você usará seus próprios dados.\nimport pandas as pd\n\n# Acessa os atributos dos nós do grafo `G`, no caso armazenados sob a chave 'node_feat'\nattributes = G['node_feat']\nlu = pd.DataFrame(attributes) # Cria o DataFrame com atributos dos nós\nlu['target'] = binary_target == 1 # Cria a coluna 'target' em lu\nlu.head()\nExecutando o método find_groups: com o grafo e seus atributos preparados, basta chamar a função com os parâmetros adequados. O método irá retornar os subgrupos identificados, acompanhados de suas métricas.\n\n\n\n\n\n\n\nObservação: esta execução foi realizada em um computador com processador Ryzen 5 1600X (3.6GHz), 16 GB de RAM DDR4 (2666MHz). Utilizamos o Twitch Dataset, contendo 1.912 nós, cada um com 128 atributos e 1 rótulo binário, além de 64.510 arestas. A execução do método levou aproximadamente 16 minutos e consumiu cerca de 8 GB de memória RAM."
  },
  {
    "objectID": "seminario2/artigo4.html#conclusão",
    "href": "seminario2/artigo4.html#conclusão",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Conclusão",
    "text": "Conclusão\nA aplicação prática do método de Local Subgroup Discovery (LSD) em grafos com atributos demonstrou sua capacidade de identificar subgrupos excepcionais em contextos locais, ao contrário do tradicional Subgroup Discovery (SD), que utiliza comparações globais. Os resultados evidenciam que o uso de grupos de referência locais permite capturar padrões mais relevantes e discriminativos, tanto em termos de estrutura quanto de atributos. O repositório disponível permite a replicação e adaptação do método a diferentes bases de dados, incentivando seu uso em problemas reais de análise de redes."
  },
  {
    "objectID": "seminario2/artigo4.html#referência",
    "href": "seminario2/artigo4.html#referência",
    "title": "Artigo 4: Local Subgroup Discovery on Attributed Network Graphs",
    "section": "Referência",
    "text": "Referência\nHeinrich, Carl Vico, Tommie Lombarts, Jules Mallens, Luc Tortike, David Wolf, and Wouter Duivesteijn. 2025. “Local Subgroup Discovery on Attributed Network Graphs.” In International Symposium on Intelligent Data Analysis, 195–208. Springer."
  },
  {
    "objectID": "seminario3/artigo5.html",
    "href": "seminario3/artigo5.html",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "",
    "text": "O artigo “Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics”, publicado em 2022 na revista Sensors, apresenta um estudo de aplicação de técnicas de aprendizado de máquina para entender o desempenho de atletas de vôlei de alto rendimento. Especificamente, os autores buscam prever a qualidade da performance técnica de cada jogador com base em informações físicas, fisiológicas e subjetivas, coletadas ao longo de uma temporada inteira.\nA proposta metodológica do trabalho é inovadora por combinar algoritmos supervisionados como XGBoost e Random Forest com técnicas de descoberta de subgrupos, para não apenas prever a performance, mas também interpretar padrões que ajudam a explicar o que leva a um bom ou mau desempenho.\nEntre os elementos analisados estão:\n\nQuantidade e altura dos saltos realizados nas semanas anteriores às partidas.\nCargas de treino muscular, registradas em kg absolutos e em % de 1RM (One Repetition Maximum).\nAnálise técnica das ações em quadra (ataques, recepções, saques), feitas por especialistas com o software Data Volley."
  },
  {
    "objectID": "seminario3/artigo5.html#sobre-o-que-trata-o-artigo",
    "href": "seminario3/artigo5.html#sobre-o-que-trata-o-artigo",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "",
    "text": "O artigo “Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics”, publicado em 2022 na revista Sensors, apresenta um estudo de aplicação de técnicas de aprendizado de máquina para entender o desempenho de atletas de vôlei de alto rendimento. Especificamente, os autores buscam prever a qualidade da performance técnica de cada jogador com base em informações físicas, fisiológicas e subjetivas, coletadas ao longo de uma temporada inteira.\nA proposta metodológica do trabalho é inovadora por combinar algoritmos supervisionados como XGBoost e Random Forest com técnicas de descoberta de subgrupos, para não apenas prever a performance, mas também interpretar padrões que ajudam a explicar o que leva a um bom ou mau desempenho.\nEntre os elementos analisados estão:\n\nQuantidade e altura dos saltos realizados nas semanas anteriores às partidas.\nCargas de treino muscular, registradas em kg absolutos e em % de 1RM (One Repetition Maximum).\nAnálise técnica das ações em quadra (ataques, recepções, saques), feitas por especialistas com o software Data Volley."
  },
  {
    "objectID": "seminario3/artigo5.html#motivação-e-contexto",
    "href": "seminario3/artigo5.html#motivação-e-contexto",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "2 Motivação e contexto",
    "text": "2 Motivação e contexto\nA motivação do estudo surge da limitação frequente de se focar apenas em estatísticas de jogo isoladas, como pontos ou erros. O artigo propõe uma abordagem multifatorial, que considera também o estado físico e mental anterior à partida — algo crucial no vôlei, esporte que exige força explosiva e gestão cuidadosa da carga de treino.\nO estudo também responde a uma necessidade prática: há muitos dados coletados em clubes de elite, mas poucos estudos que integram essas informações ao desempenho técnico. Assim, o trabalho aproxima ciência de dados e prática esportiva."
  },
  {
    "objectID": "seminario3/artigo5.html#como-foi-feito-o-estudo",
    "href": "seminario3/artigo5.html#como-foi-feito-o-estudo",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "3 Como foi feito o estudo",
    "text": "3 Como foi feito o estudo\n\n3.1 Participantes e acompanhamento\nDurante uma temporada competitiva de 24 semanas, foram acompanhados 25 jogadores da seleção masculina holandesa de vôlei. Apenas 17 jogadores com dados completos foram analisados.\n\n\n3.2 Coleta e tipos de dados\nOs dados foram coletados por:\n\nG-VERT: dispositivo para saltos (volume, altura e tipo: baixo, médio, alto).\nQuestionários subjetivos (ex.: RPE): percepção de esforço após treinos.\nAutoavaliações diárias: fadiga, sono, humor.\nRegistros de treino de força: pesos por grupo muscular.\nSoftware Data Volley 4: avaliação técnica das ações de jogo (notas de 0 a 10).\n\n\n\n3.3 Pré-processamento e engenharia de atributos\nOs dados foram agregados em janelas móveis de 7, 14 e 28 dias anteriores a cada jogo. Foram calculadas médias, desvios padrão, quartis, etc., resultando em 237 preditores, como:\n\n72 preditores de saltos.\n81 de exercícios de força.\n48 de bem-estar subjetivo.\n27 de carga de treino (monotonia, strain).\n9 de frequência de treinos."
  },
  {
    "objectID": "seminario3/artigo5.html#modelagem-e-análise-de-padrões",
    "href": "seminario3/artigo5.html#modelagem-e-análise-de-padrões",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "4 Modelagem e análise de padrões",
    "text": "4 Modelagem e análise de padrões\n\n4.1 Modelos preditivos\n\nXGBoost e Random Forest foram usados para prever notas de ações ofensivas (ataque e saque) e defensivas (recepção e bloqueio).\nMétrica: Erro Absoluto Médio (MAE).\n\n\n\n4.2 Descoberta de Subgrupos\nUsada para identificar padrões interpretáveis que distinguem boa e má performance. Exemplo: jogadores com baixa variação em saltos altos nas últimas 4 semanas tendem a performar pior em recepções."
  },
  {
    "objectID": "seminario3/artigo5.html#principais-resultados-desvendando-os-fatores-chave-do-desempenho",
    "href": "seminario3/artigo5.html#principais-resultados-desvendando-os-fatores-chave-do-desempenho",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "5 Principais Resultados: Desvendando os Fatores-Chave do Desempenho",
    "text": "5 Principais Resultados: Desvendando os Fatores-Chave do Desempenho\n\n5.1 Desempenho ofensivo\n\nPositivo: Exercícios de membros inferiores &gt;90kg nas últimas 4 semanas → melhor ataque.\nNegativo:\n\nTreinamento pesado de membros superiores (&gt;0.9% do 1RM).\nAlta variação de carga de corpo inteiro (&gt;17.6kg).\nBaixa altura de saltos ou pouca variação em saltos altos.\n\n\n\n\n5.2 Desempenho defensivo\n\nVariação (&gt;9.75) e excesso (média ≥11.6) de saltos altos nas 2 semanas anteriores → pior desempenho no passe.\n\n\n\n5.3 Bem-estar subjetivo\nNão apresentou relação estatisticamente significativa com desempenho.\n\n\n5.4 Modelos preditivos\nRedução no MAE de: - 36-47% no desempenho ofensivo. - 59-74% no defensivo, em relação ao modelo de base."
  },
  {
    "objectID": "seminario3/artigo5.html#aplicações-e-implicações",
    "href": "seminario3/artigo5.html#aplicações-e-implicações",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "6 Aplicações e Implicações",
    "text": "6 Aplicações e Implicações\n\n6.1 Personalização de Treinamento\n\nAtacantes: foco em força de membros inferiores, evitar sobrecarga nos membros superiores.\nPassadores: controlar variação e volume de saltos altos próximos ao jogo.\n\n\n\n6.2 Generalização da metodologia\nA metodologia pode ser usada em:\n\nEducação: desempenho de alunos em função de rotina de estudo e descanso.\nEmpresas: impacto de tarefas, horários e descanso na produtividade."
  },
  {
    "objectID": "seminario3/artigo5.html#riscos-e-limitações",
    "href": "seminario3/artigo5.html#riscos-e-limitações",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "7 Riscos e Limitações",
    "text": "7 Riscos e Limitações\n\n7.1 Limitações metodológicas\n\nAmostra pequena (17 atletas).\nPoucos dados para algumas ações (ex.: bloqueios).\nModelos complexos não superaram drasticamente modelos simples.\nNão se considerou o nível da partida (amistoso vs. torneio).\n\n\n\n7.2 Questões éticas\n\nControle excessivo: risco de ambientes opressivos.\nPrivacidade: dados sensíveis como humor e fadiga devem ser protegidos.\nO estudo não compartilhou dados publicamente por serem da NeVoBo."
  },
  {
    "objectID": "seminario3/artigo5.html#conclusão-o-potencial-e-a-responsabilidade-da-ia-no-esporte",
    "href": "seminario3/artigo5.html#conclusão-o-potencial-e-a-responsabilidade-da-ia-no-esporte",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "8 Conclusão: O Potencial e a Responsabilidade da IA no Esporte",
    "text": "8 Conclusão: O Potencial e a Responsabilidade da IA no Esporte\nO estudo mostra o poder da IA na ciência do esporte, especialmente ao integrar dados objetivos e subjetivos para prever e explicar o desempenho. As descobertas permitem intervenções práticas e personalizadas, mas também trazem responsabilidades éticas — como proteger a privacidade e evitar o uso abusivo da vigilância.\nO equilíbrio entre precisão técnica e sensibilidade humana será crucial para que a tecnologia empodere atletas e não os controle."
  },
  {
    "objectID": "seminario3/artigo5.html#referência-bibliográfica",
    "href": "seminario3/artigo5.html#referência-bibliográfica",
    "title": "Artigo 5: Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics",
    "section": "9 Referência Bibliográfica",
    "text": "9 Referência Bibliográfica\nde Leeuw, A.-W., van Baar, R., Knobbe, A., & van der Zwaard, S. (2022). Modeling Match Performance in Elite Volleyball Players: Importance of Jump Load and Strength Training Characteristics. Sensors, 22(20), 7996. https://doi.org/10.3390/s22207996"
  }
]