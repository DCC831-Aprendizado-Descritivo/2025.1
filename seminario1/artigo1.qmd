---
title: "Artigo 1: Differentiable Pattern Set Mining"
page-layout: full

date: "2025-06-13"
date-format: long
lang: "pt-BR"
format:
  html:
    number-sections: true
    code-fold: true
    code-tools: true
    highlight-style: github
    fig-width: 8
    fig-height: 6
    fig-align: center
    fig-format: png
    fig-cap-location: top
    css: src/art1/artigo1.css
bibliography: src/art1/referencias.bib
# csl: src/art1/abntex.csl
crossref:
  fig-labels: arabic
  fig-prefix: Figura
  tbl-prefix: Tabela
  eq-prefix: Equação
---

## Introdução: o que é mineração de padrões?

Mineração de padrões é uma área de Aprendizado Descritivo que objetiva encontrar informações interpretáveis de grandes bancos de dados. Tal objetivo é alcançado por meio da mineração de "padrões" ou "regras" que definem conjuntos relevantes, seja em frequência ou em importância.

As aplicações de mineração de padrões são variadas, desde ciências naturais como Biologia e Química, estudos estatísticos e matemáticos e análises societais e comportamentais.

Infelizmente, os algoritmos para mineração de padrões são extremamente custosos, sendo duplamente exponencial no _número de atributos_. Além disso, eles sofrem de redundância nas respostas, muitas vezes repetindo padrões similares e de relevância das respostas, sofrendo com overfitting ou underfitting.

## BinaPs

Para resolver a problemática acima, o algoritmo introduz o **BinaPs**, uma solução que vê o problema por meio da lente de aprendizado de máquina ao invés de construção de conjuntos. Para entender melhor as duas perspectivas, considere as diferenças principais do **BinaPs** para algoritmos tradicionais:

- **Apriori, Eclat, FP-Growth**:
  - Padrões escolhidos por frequência
  - Padrões redundantes encontrados
  - Apenas otimizados por heurísticas
  - Calculado na CPU
- **BinaPs**:
  - Funções diferenciáveis para descoberta de padrões
  - Padrões menos redundantes
  - GPU para cálculos
  - Significativamente mais escalável
  - Otimizável por parâmetros de entrada como learning rate

### Funcionamento

Inspirado por decoders e encoders, o algoritmo tem como objetivo obter os atributos de um item, codificar eles em o mesmo número ou menos de neurônios no processo e retornar para o número inicial como representado pela @fig-encdec.

![Encoder e Decoder - Fonte: o autor][Imagem: Figura 1 - Encoder e Decoder]{#fig-encdec width=90% fig-align="center"}

O BinaPs contém algumas otimizações e considerações quando considerado com outras rede neurais, dentre elas:

- Os neurônios e pesos finais são binários $\{0, 1\}$
- Viés é usado para evitar overfitting
- Normalização da função de perda para evitar saídas de apenas $\{1\}$ ou $\{0\}$ em bases densas e esparsas.
- Gated Straight-Through Estimator para não penalizar os neurônios desligados

Após essas mudanças, o algoritmo funciona como descrito pela @fig-binasps.

![Funcionamento do **BinaPs** [^1]][Imagem: Figura 2]{#fig-binasps}

### Experimentos

O **BinaPs** foi comparado com três outros competidores na área de mineração de dados: **Asso, Slim e Desc**, que usam matrizes booleanas, mineração de conjuntos por MDL e maximum entropy modeling respectivamente. Os experimentos foram divididos em duas categorias: sintéticos e reais.

#### Sintéticos

Dados sintéticos foram escolhidos pois é possível inserir ou estudar padrões reais nos dados previamente, podendo assim comparar os resultados dos algoritmos com o "ground truth", ou seja, o que assumimos ser a verdade.

Para medir a performance dos algoritmos foi usado a **F1-score**, uma medida calculada pela média harmônica do _precision_ e do _recall_, comumente usada em aprendizado de máquina para avaliar a performance de modelos.

##### Escalabilidade

::: {#fig-graficos-A layout-ncol=2}
![Features: F1-Score][Imagem: Figura 3a]{#fig-F1-Score-features}

![Features: Time in Seconds][Imagem: Figura 3b]{#fig-time-in-seconds-features}

Estatísticas BinaPs, Asso, Slim e Desc: Features [^1]
:::

Com um número crescente de features (atributos), o **BinaPs** se mostra mais preciso (@fig-F1-Score-features) e menos custoso (@fig-time-in-seconds-features) em tempo que os outros três, com o **Asso** se assemelhando a ele em resultados, mas não em performance, eventualmente não sendo capaz de rodar datasets maiores.

##### Resistência a ruídos

Muitas vezes dados reais possuem ruídos, seja de medidas errôneas, problemas no dataset ou imprevisibilidade dos dados. Para testar se os algoritmos são resistentes a tais cenários foram inseridos quantidades crescentes de ruídos nos databases testados com os seguintes resultados:

::: {#fig-graficos-B layout-ncol=2}
![Ruídos: F1-Score][Imagem: Figura 4a]{#fig-F1-Score-noise}

![Ruídos: Time in Seconds][Imagem: Figura 4b]{#fig-time-in-seconds-noise}

Estatísticas BinaPs, Asso, Slim e Desc: Ruídos [^1]
:::

Ao analisar os gráficos, ambos o **BinaPs** e o **Asso** são resistentes a ruídos em ambos F1-score (@fig-F1-Score-noise) e tempo de execução (@fig-time-in-seconds-noise). Já ambos **Slim** e **Desc** são afetados por ruídos no F1-score (@fig-F1-Score-noise) e o **Slim** em tempo de execução (@fig-time-in-seconds-noise) também.

##### Operabilidade com Samples

![F1-Score $\times$ Samples [^1]][Imagem: Figura 5]{#fig-F1-Score-samples}

Para testar a capacidade do **BinaPs** de operar com poucos samples, também foi feito testes com quantidades crescentes de dados para ver sua performance.

Mesmo com um número bem reduzido de samples o **BinaPs** foi capaz de conseguir uma pontuação boa (@fig-F1-Score-samples), melhorando marginalmente com mais samples até estabilizar perto do final do gráfico.

#### Reais

Foram usados 5 bases de dados reais para o comparativo entre os algoritmos:

- **DNA:** Dados de amplificação de DNA
- **Accidents:** Dados de acidentes belgas
- **Instacart:** Dados de compras de supermercado online
- **Korsarak:** Dados de cliques em um site de notícias hungaro
- **Genomes:** Dados de indivíduos no projeto 1000 genomes

##### Análise Qualitativa

Ao contrário dos dados sintéticos, não temos como saber quais padrões são "corretos" ou "incorretos". Dessa forma, a análise é mais subjetiva. Primeiro comparamos o número de padrões encontrados (@tbl-padroes) nos 5 bancos de dados (@tbl-Analise) e o tempo de execução de cada algoritmo (@tbl-tempo).

::: {#tbl-Analise layout-ncol=3}

| $Dataset$ | $\#\ rows$ | $\#\ cols$ |
| :-------- | ---------: | ---------: |
| DNA       |     $2458$ |      $391$ |
| Accidents |   $340183$ |      $468$ |
| Instacart |  $2704831$ |     $1235$ |
| Kosarak   |   $990002$ |    $41270$ |
| Genomes   |     $2504$ |   $226623$ |

: Linhas e colunas dos datasets {#tbl-linhas-colunas}

| $Asso$ | **$BinaPs$** | $Desc$ |  $Slim$ |
| -----: | -----------: | -----: | ------: |
|  $134$ |    **$131$** |  $345$ |   $281$ |
|  $133$ |     **$78$** |  $215$ | $12261$ |
|  $n/a$ |    **$328$** |  $712$ |  $8119$ |
|  $n/a$ |    **$302$** |  $n/a$ |   $n/a$ |
|  $n/a$ |     **$42$** |  $n/a$ |   $n/a$ |

: Número de padrões encontrados {#tbl-padroes}

|   $Asso$ | **$BinaPs$** |   $Desc$ |   $Slim$ |
| -------: | -----------: | -------: | -------: |
|    $4 m$ |   **$26 s$** |   $20 s$ |    $2 s$ |
|   $12 h$ |    **$6 m$** |   $14 m$ |   $21 h$ |
| $\infty$ |   **$44 m$** |   $25 m$ |    $8 h$ |
| $\infty$ |    **$5 h$** | $\infty$ | $\infty$ |
| $\infty$ |    **$9 m$** | $\infty$ | $\infty$ |

: Comparativo de tempo {#tbl-tempo}

Tabela comparativa dos datasets [^1]
:::

Em alguns casos, os outros algoritmos não conseguiram rodar em até 3 dias ou com 256GB de RAM. Tais cenários foram marcados com $n/a$ ou $\infty$ (@tbl-padroes).

O **BinaPs** retornou resultados menos redundantes, facilitando interpretabilidade. Além disso, foram notados algumas falhas em outros algoritmos, dentre eles:

- **Asso** não conseguiu escalar bem
- **Slim** encontrou milhares de resultados redundantes
- **Desc** sofre de underfitting e só retornou padrões de tamanho 2 no Instacart.

##### Análise Quantitativa

Foi feita uma análise quantitativa em 3 dos bancos de dados listados acima. Duas comparativas (DNA, Instacart) e uma individual.

**DNA:** _BinaPs_ e _Asso_ encontraram blocos de DNA e conjuntos desses blocos como estruturas, representando elementos biologicamente relevantes. _Slim_ começa a encontrar blocos, mas faz um overfitting para padrões grandes demais que acontecem raramente e não tem estrutura evidente de blocos. _Desc_ encontra padrões pequenos apenas graças a um underfitting.

**Instacart:** _BinaPs_ encontra padrões grandes com combinações arbitrárias como um conjunto de 12 frutas comprados de formas diferentes. O _Slim_ quebra este conjunto em milhares de padrões menores. _Desc_ faz underfitting novamente, encontrando padrões de tamanho 2 apenas. Além disso, o _BinaPs_ também encontrou padrões pequenos que se assemelham à lista de ingredientes de pratos culinários, mostrando relevância novamente.

**Genomes:** De acordo com os autores, esta seção obteve os resultados mais promissores, sendo um motivador principal para o estudo.

Foi possível encontrar padrões antes conhecidos de genes relacionados, como os NUCB2 e ABCC8 relacionados à diabetes tipo 2 e pressão alta em populações japonesas. Porém, muitas vezes esses grupos conhecidos estavam adjuntos a outros elementos, como o NCR3LG1 e ROMO1. Isso demonstra a possibilidade do uso do algoritmo para estabelecer relações novas que podem ser estudadas no futuro.

Outro exemplo foi o dos genes SF3A1, RRP7A e Z82190 onde os dois primeiros codificam proteínas que são parte do ribossomo (que por sua conta é a fábrica de proteínas da célula), já o terceiro não é caracterizado. O padrão destes juntos é uma dica que pode guiar estudos futuros nessa área.

Por final, ao analisar padrões de variantes entre alelos, o BinaPs sugere que variantes raras normalmente acompanhadas de comuns podem acontecer de um para o outro "$0 \mid 1$" como na literatura, mas muitas vezes também acontece em "$1 \mid 0$", ou seja, os raros no alelo que antes havia comuns e vice-versa. Os autores não sabem se isso têm significado biológico, sugerindo que isso seja analisado por profissionais da área.

### Execução

O artigo nos entrega um [Link para o repositório][Link_BinaPs]. Para rodar o BinaPs em uma máquina comum é necessário:

#### Gerar dados sintéticos

1. Baixar e descompactar os arquivos
2. Instalar as dependências (Pytorch, Scipy, Pandas, Numpy, R)
3. Alterar arquivo `genSynth.sh` para parâmetros de uma máquina convencional (8 a 32GB de RAM)
4. Executar `./genSynth.sh`

O resultado é um arquivo .dat com os dados em formato de matriz binária esparsa. Ou seja, para cada linha, os elementos da linha são os indices das posições com valor 1 na matriz original.

##### Executar o algoritmo

Para executar basta chamar `python main.py --input <arquivo.dat> --batch_size <32 ou 64>` que pode também ser adjunto dos parâmetros apresentados na @tbl-parametros-binasps.

| Parâmetro           | Tipo    | Valor padrão | Descrição                                                            |
| :------------------ | :------ | -----------: | :------------------------------------------------------------------- |
| `--save_model`      | `bool`  |      $False$ | Se ativado, salva o modelo treinado para disco                       |
| `--gamma`           | `float` |        $0.1$ | Fator de decaimento do learning rate (usado no agendador de LR)      |
| `--lr`              | `float` |       $0.01$ | Taxa de aprendizado (learning rate)                                  |
| `--train_set_size`  | `float` |        $0.9$ | Proporção dos dados usada para treinamento                           |
| `--weight_decay`    | `float` |        $0.0$ | Fator de penalização L2 (regularização dos pesos)                    |
| `--batch_size`      | `int`   |         $64$ | Tamanho do batch para treinamento                                    |
| `--epochs`          | `int`   |         $10$ | Número de épocas de treinamento                                      |
| `--hidden_dim`      | `int`   |         $-1$ | Número de neurônios ocultos (usa #features se -1)                    |
| `--log_interval`    | `int`   |         $10$ | Intervalo (em batches) para exibir logs de treino                    |
| `--seed`            | `int`   |          $1$ | Semente para reprodutibilidade (random seed)                         |
| `--test_batch_size` | `int`   |         $64$ | Tamanho do batch para teste                                          |
| `--thread_num`      | `int`   |         $16$ | Número de threads a serem usadas no treinamento                      |
| `--input (-i)`      | `str`   |  Obrigatório | Caminho para o arquivo de entrada (dados usados para treino e teste) |

: Parâmetros do BinaPs [^2] {#tbl-parametros-binasps}

##### Saída do algoritmo

Após o treinamento marcado pelas "Epoch" temos alguns dados como a "Average loss" e a "Accuracy" seguido dos padrões dispostos na @fig-exec-binaps.

![Resultado da execução do BinaPs [^2]][Imagem: Figura 6]{#fig-exec-binaps}

Cada linha dos padrões mostra um padrão que foi reconstruído, como por exemplo o $[45, 46, 47, 48, 49]$ seguido de dois números: O primeiro o número de amostras que ativaram **todos** os bits e o segundo amostras que ativaram **metade** dos bits do padrão. Ou seja, $4404$ vezes os bits $45$ a $49$ foram completamente ativados e $4425$ vezes parcialmente ativados (metade).

**Conclusão:** O padrão $[45-49]$ é altamente confiável pois aparece em mais de 99% das vezes que é parcialmente ativado, indicando forte consistência local nos dados.

### Impacto Social

#### Transparência e Justiça

O método do BinaPs é significativamente mais interpretável que outras soluções usando inteligência artificial ou caixas-pretas. Tal transparência entrega um grau de confiança maior aos resultados e pode levar a estudos e entendimentos novos relacionados à area investigada.

Além disso, como o processo é transparente, ele se torna mais fácil de ser ajustado por profissionais para evitar vieses indesejados como os de cor, gênero, raça, classe e outros.

#### Cenários de Uso

Similarmente a outros métodos de mineração de padrões, os usos são bem vastos, mas dessa vez eles são beneficiados também pela transparência. Aqui estão alguns deles:

- **Saúde**
  - Estudo de biomarcadores relevantes para diagnósticos
  - Detecção de padrões comuns à doenças como sintomas
- **Cidades inteligentes**
  - Análise de padrões de tráfego para otimização do transporte
  - Mineração de padrões no uso de serviços públicos
- **Educação**
  - Análise de trajetórias acadêmicas para politicas de incentivo
  - Estudo de consumo de cursos para personalização de trilhas
- **Comércio**
  - Padrões de compras para sistemas de recomendação
  - Perfis de consumidores para marketing personalizado
- **Governos e Organizações**
  - Detecção de padrões de fraude em transações como as bancárias
  - Estudo de padrões comportamentais para prevenção de crimes

#### Riscos

O BinaPs é uma ferramenta. Da mesma forma que é necessário cuidado ao usar um martelo, é importante saber os riscos que tomamos ao usar uma ferramenta dessas para evitar problemas. Um dos maiores riscos são os de **dados enviesados**.

Grande porção dos dados usados são daqueles que mais coletam dados, que tendem a ser países de primeiro mundo nas classes media e alta. Além disso, muitos dados são enviesados por cor, raça, gênero e outros fatores que não devem serem analisados como causalidade por motivos éticos.

Exemplos de dados enviesados incluem a ferramenta de triagem de currículos da Amazon, que aprendeu e manteve o preconceito de gênero que estava presente antes de sua implementação, o que desfavoreceu o gênero feminino.

Além disso, há áreas de implementação que não podem ter vieses como por exemplo:

- Concessão de crédito
  - Discriminação, Desinformação, Privacidade, Over-Marketing
- Precificação de seguros e planos de saúde
  - Diferenciação de grupos por fatores pessoais, étnicos, etários ou de doenças.

Em ambos os casos, são necessárias políticas como a LGPD para garantir a anonimização dos dados e a publicação de métodos e entradas utilizados para que especialistas possam discutir as questões éticas do uso dos dados específicos utilizados.

## Conclusão

O BinaPs é um algoritmo de mineração de padrões inovador, com características transparentes e eficientes em relação à competição. Seu código é aberto e bem explicado com um gerador de dados sintéticos incluso e alguns estudos preliminares de áreas que podem beneficiar do seu uso. Se for usado como uma ferramenta de forma responsável, ele pode ser um pioneiro em estudos, análises e sumarizações de dados massivos.

## Links de Interesse

- **Título:** Differentiable Pattern Set Mining - @Fischer_2021
- **Artigo:** [DOI][Link_artigo], [PDF][Link_artigo_pdf], [MP4 (Apresentação dos Autores)][Apresentação dos Autores]

## Referências

::: {#refs}
:::

<!-- Links -->

[Link_artigo]: https://doi.org/10.1145/3447548.3467348
[Link_artigo_pdf]: https://dl.acm.org/doi/pdf/10.1145/3447548.3467348
[Apresentação dos Autores]: https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3447548.3467348&file=differentiable_pattern_set_mining-jonas_fischer-jilles_vreeken-38957922-489z.mp4
[Link_BinaPs]: https://eda.rg.cispa.io/prj/binaps

<!-- Imagens -->

[Imagem: Figura 1 - Encoder e Decoder]: src/art1/Figura1.svg
[Imagem: Figura 2]: src/art1/Figura2.png
[Imagem: Figura 3a]: src/art1/Figura3a.png
[Imagem: Figura 3b]: src/art1/Figura3b.png
[Imagem: Figura 4a]: src/art1/Figura4a.png
[Imagem: Figura 4b]: src/art1/Figura4b.png
[Imagem: Figura 5]: src/art1/Figura5.png
[Imagem: Figura 6]: src/art1/Figura6.png

<!-- Referências -->

[^1]: por @Fischer_2021 sob a licensa [CC BY 4.0][License].

[License]: https://creativecommons.org/licenses/by/4.0/

[^2]: Fonte: grupo hacker.
